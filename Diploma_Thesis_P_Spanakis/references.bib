@misc{systematicsurveypromptengineering,
  title         = {A Systematic Survey of Prompt Engineering in Large Language Models: Techniques and Applications},
  author        = {Pranab Sahoo and Ayush Kumar Singh and Sriparna Saha and Vinija Jain and Samrat Mondal and Aman Chadha},
  year          = {2025},
  eprint        = {2402.07927},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2402.07927}
}

@misc{surveypromptengineeringmethods,
  title         = {A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks},
  author        = {Shubham Vatsal and Harsh Dubey},
  year          = {2024},
  eprint        = {2407.12994},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2407.12994}
}

@misc{liu2021pretrainpromptpredictsystematic,
  title         = {Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing},
  author        = {Pengfei Liu and Weizhe Yuan and Jinlan Fu and Zhengbao Jiang and Hiroaki Hayashi and Graham Neubig},
  year          = {2021},
  eprint        = {2107.13586},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2107.13586}
}

@misc{promptreportsystematicsurvey,
  title         = {The Prompt Report: A Systematic Survey of Prompt Engineering Techniques},
  author        = {Sander Schulhoff and Michael Ilie and Nishant Balepur and Konstantine Kahadze and Amanda Liu and Chenglei Si and Yinheng Li and Aayush Gupta and HyoJung Han and Sevien Schulhoff and Pranav Sandeep Dulepet and Saurav Vidyadhara and Dayeon Ki and Sweta Agrawal and Chau Pham and Gerson Kroiz and Feileen Li and Hudson Tao and Ashay Srivastava and Hevander Da Costa and Saloni Gupta and Megan L. Rogers and Inna Goncearenco and Giuseppe Sarli and Igor Galynker and Denis Peskoff and Marine Carpuat and Jules White and Shyamal Anadkat and Alexander Hoyle and Philip Resnik},
  year          = {2025},
  eprint        = {2406.06608},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2406.06608}
}

@misc{templates,
  title         = {From Prompts to Templates: A Systematic Prompt Template Analysis for Real-world LLMapps},
  author        = {Yuetian Mao and Junjie He and Chunyang Chen},
  year          = {2025},
  eprint        = {2504.02052},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE},
  url           = {https://arxiv.org/abs/2504.02052}
}

@misc{kojima2023largelanguagemodelszeroshot,
  title         = {Large Language Models are Zero-Shot Reasoners},
  author        = {Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
  year          = {2023},
  eprint        = {2205.11916},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2205.11916}
}

@misc{brown2020languagemodelsfewshotlearners,
  title         = {Language Models are Few-Shot Learners},
  author        = {Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
  year          = {2020},
  eprint        = {2005.14165},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2005.14165}
}

@misc{lu2022fantasticallyorderedpromptsthem,
  title         = {Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity},
  author        = {Yao Lu and Max Bartolo and Alastair Moore and Sebastian Riedel and Pontus Stenetorp},
  year          = {2022},
  eprint        = {2104.08786},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2104.08786}
}

@misc{cot-figure,
  title         = {When do you need Chain-of-Thought Prompting for ChatGPT?},
  author        = {Jiuhai Chen and Lichang Chen and Heng Huang and Tianyi Zhou},
  year          = {2023},
  eprint        = {2304.03262},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2304.03262}
}

@misc{cotpromptingelicitsreasoning,
  title         = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author        = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
  year          = {2023},
  eprint        = {2201.11903},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2201.11903}
}


@misc{understandingchainofthoughtpromptingempirical,
  title         = {Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters},
  author        = {Boshi Wang and Sewon Min and Xiang Deng and Jiaming Shen and You Wu and Luke Zettlemoyer and Huan Sun},
  year          = {2023},
  eprint        = {2212.10001},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2212.10001}
}

@misc{automaticchainthoughtprompting,
  title         = {Automatic Chain of Thought Prompting in Large Language Models},
  author        = {Zhuosheng Zhang and Aston Zhang and Mu Li and Alex Smola},
  year          = {2022},
  eprint        = {2210.03493},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2210.03493}
}

@misc{scalinglawsneurallanguage,
  title         = {Scaling Laws for Neural Language Models},
  author        = {Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
  year          = {2020},
  eprint        = {2001.08361},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2001.08361}
}

@misc{inversescalingbiggerisnt,
  title         = {Inverse Scaling: When Bigger Isn't Better},
  author        = {Ian R. McKenzie and Alexander Lyzhov and Michael Pieler and Alicia Parrish and Aaron Mueller and Ameya Prabhu and Euan McLean and Aaron Kirtland and Alexis Ross and Alisa Liu and Andrew Gritsevskiy and Daniel Wurgaft and Derik Kauffman and Gabriel Recchia and Jiacheng Liu and Joe Cavanagh and Max Weiss and Sicong Huang and The Floating Droid and Tom Tseng and Tomasz Korbak and Xudong Shen and Yuhui Zhang and Zhengping Zhou and Najoung Kim and Samuel R. Bowman and Ethan Perez},
  year          = {2024},
  eprint        = {2306.09479},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2306.09479}
}

@misc{olsson2022incontextlearninginductionheads,
  title         = {In-context Learning and Induction Heads},
  author        = {Catherine Olsson and Nelson Elhage and Neel Nanda and Nicholas Joseph and Nova DasSarma and Tom Henighan and Ben Mann and Amanda Askell and Yuntao Bai and Anna Chen and Tom Conerly and Dawn Drain and Deep Ganguli and Zac Hatfield-Dodds and Danny Hernandez and Scott Johnston and Andy Jones and Jackson Kernion and Liane Lovitt and Kamal Ndousse and Dario Amodei and Tom Brown and Jack Clark and Jared Kaplan and Sam McCandlish and Chris Olah},
  year          = {2022},
  eprint        = {2209.11895},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2209.11895}
}

@misc{zhang2023positivescalingnegationimpacts,
  title         = {Beyond Positive Scaling: How Negation Impacts Scaling Trends of Language Models},
  author        = {Yuhui Zhang and Michihiro Yasunaga and Zhengping Zhou and Jeff Z. HaoChen and James Zou and Percy Liang and Serena Yeung},
  year          = {2023},
  eprint        = {2305.17311},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2305.17311}
}

@article{kahneman1973prediction,
  author  = {Kahneman, Daniel and Tversky, Amos},
  title   = {On the Psychology of Prediction},
  journal = {Psychological Review},
  year    = {1973},
  volume  = {80},
  number  = {4},
  pages   = {237--251}
}

@misc{reasoningrecitingexploringcapabilities,
  title         = {Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks},
  author        = {Zhaofeng Wu and Linlu Qiu and Alexis Ross and Ekin Akyürek and Boyuan Chen and Bailin Wang and Najoung Kim and Jacob Andreas and Yoon Kim},
  year          = {2024},
  eprint        = {2307.02477},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2307.02477}
}

@misc{reasoningsurvey,
  title         = {Reasoning with Language Model Prompting: A Survey},
  author        = {Shuofei Qiao and Yixin Ou and Ningyu Zhang and Xiang Chen and Yunzhi Yao and Shumin Deng and Chuanqi Tan and Fei Huang and Huajun Chen},
  year          = {2023},
  eprint        = {2212.09597},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2212.09597}
}

@inproceedings{reasoning-machine,
  title     = {Machine Reasoning: Technology, Dilemma and Future},
  author    = {Duan, Nan  and
               Tang, Duyu  and
               Zhou, Ming},
  editor    = {Villavicencio, Aline  and
               Van Durme, Benjamin},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.emnlp-tutorials.1/},
  doi       = {10.18653/v1/2020.emnlp-tutorials.1},
  pages     = {1--6},
  abstract  = {Machine reasoning research aims to build interpretable AI systems that can solve problems or draw conclusions from what they are told (i.e. facts and observations) and already know (i.e. models, common sense and knowledge) under certain constraints. In this tutorial, we will (1) describe the motivation of this tutorial and give our definition on machine reasoning; (2) introduce typical machine reasoning frameworks, including symbolic reasoning, probabilistic reasoning, neural-symbolic reasoning and neural-evidence reasoning, and show their successful applications in real-world scenarios; (3) talk about the dilemma between black-box neural networks with state-of-the-art performance and machine reasoning approaches with better interpretability; (4) summarize the content of this tutorial and discuss possible future directions.}
}

@misc{clark2020transformerssoftreasonerslanguage,
  title         = {Transformers as Soft Reasoners over Language},
  author        = {Peter Clark and Oyvind Tafjord and Kyle Richardson},
  year          = {2020},
  eprint        = {2002.05867},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2002.05867}
}

@misc{chen2025justlogiccomprehensivebenchmarkevaluating,
  title         = {JustLogic: A Comprehensive Benchmark for Evaluating Deductive Reasoning in Large Language Models},
  author        = {Michael K. Chen and Xikun Zhang and Dacheng Tao},
  year          = {2025},
  eprint        = {2501.14851},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2501.14851}
}

@inproceedings{bowen-etal-2024-inductive,
  title     = {A Comprehensive Evaluation of Inductive Reasoning Capabilities and Problem Solving in Large Language Models},
  author    = {Bowen, Chen  and
               S{\ae}tre, Rune  and
               Miyao, Yusuke},
  editor    = {Graham, Yvette  and
               Purver, Matthew},
  booktitle = {Findings of the Association for Computational Linguistics: EACL 2024},
  month     = mar,
  year      = {2024},
  address   = {St. Julian{'}s, Malta},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.findings-eacl.22/},
  pages     = {323--339},
  abstract  = {Inductive reasoning is fundamental to both human and artificial intelligence. The inductive reasoning abilities of current Large Language Models (LLMs) are evaluated in this research.We argue that only considering induction of rules is too narrow and unrealistic, since inductive reasoning is usually mixed with other abilities, like rules application, results/rules validation, and updated information integration.We probed the LLMs with a set of designed symbolic tasks and found that even state-of-the-art (SotA) LLMs fail significantly, showing the inability of LLMs to perform these intuitively simple tasks.Furthermore, we found that perfect accuracy in a small-size problem does not guarantee the same accuracy in a larger-size version of the same problem, provoking the question of how we can assess the LLMs' actual problem-solving capabilities.We also argue that Chain-of-Thought prompts help the LLMs by decomposing the problem-solving process, but the LLMs still learn limitedly.Furthermore, we reveal that few-shot examples assist LLM generalization in out-of-domain (OOD) cases, albeit limited. The LLM starts to fail when the problem deviates from the provided few-shot examples.}
}

@misc{li2025mirageevaluatingexplaininginductive,
  title         = {MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models},
  author        = {Jiachun Li and Pengfei Cao and Zhuoran Jin and Yubo Chen and Kang Liu and Jun Zhao},
  year          = {2025},
  eprint        = {2410.09542},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2410.09542}
}

@inproceedings{causalbench,
  title     = {{C}ausal{B}ench: A Comprehensive Benchmark for Evaluating Causal Reasoning Capabilities of Large Language Models},
  author    = {Wang, Zeyu},
  editor    = {Wong, Kam-Fai  and
               Zhang, Min  and
               Xu, Ruifeng  and
               Li, Jing  and
               Wei, Zhongyu  and
               Gui, Lin  and
               Liang, Bin  and
               Zhao, Runcong},
  booktitle = {Proceedings of the 10th SIGHAN Workshop on Chinese Language Processing (SIGHAN-10)},
  month     = aug,
  year      = {2024},
  address   = {Bangkok, Thailand},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.sighan-1.17/},
  pages     = {143--151},
  abstract  = {Causal reasoning, a core aspect of human cognition, is essential for advancing large language models (LLMs) towards artificial general intelligence (AGI) and reducing their propensity for generating hallucinations. However, existing datasets for evaluating causal reasoning in LLMs are limited by narrow domain coverage and a focus on cause-to-effect reasoning through textual problems, which does not comprehensively assess whether LLMs truly grasp causal relationships or merely guess correct answers. To address these shortcomings, we introduce a novel benchmark that spans textual, mathematical, and coding problem domains. Each problem is crafted to probe causal understanding from four perspectives: cause-to-effect, effect-to-cause, cause-to-effect with intervention, and effect-to-cause with intervention. This multi-dimensional evaluation method ensures that LLMs must exhibit a genuine understanding of causal structures by correctly answering questions across all four dimensions, mitigating the possibility of correct responses by chance. Furthermore, our benchmark explores the relationship between an LLM`s causal reasoning performance and its tendency to produce hallucinations. We present evaluations of state-of-the-art LLMs using our benchmark, providing valuable insights into their current causal reasoning capabilities across diverse domains. The dataset is publicly available for download at https://huggingface.co/datasets/CCLV/CausalBench}
}

@misc{jin2024largelanguagemodelsinfer,
  title         = {Can Large Language Models Infer Causation from Correlation?},
  author        = {Zhijing Jin and Jiarui Liu and Zhiheng Lyu and Spencer Poff and Mrinmaya Sachan and Rada Mihalcea and Mona Diab and Bernhard Schölkopf},
  year          = {2024},
  eprint        = {2306.05836},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2306.05836}
}

@misc{qin2024relevantrandomllmstruly,
  title         = {Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?},
  author        = {Chengwei Qin and Wenhan Xia and Tan Wang and Fangkai Jiao and Yuchen Hu and Bosheng Ding and Ruirui Chen and Shafiq Joty},
  year          = {2024},
  eprint        = {2404.12728},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2404.12728}
}

@misc{sultan2023lifecircusclownsautomatically,
  title         = {Life is a Circus and We are the Clowns: Automatically Finding Analogies between Situations and Processes},
  author        = {Oren Sultan and Dafna Shahaf},
  year          = {2023},
  eprint        = {2210.12197},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2210.12197}
}

@inproceedings{commonsenseqa,
  title     = {{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge},
  author    = {Talmor, Alon  and
               Herzig, Jonathan  and
               Lourie, Nicholas  and
               Berant, Jonathan},
  editor    = {Burstein, Jill  and
               Doran, Christy  and
               Solorio, Thamar},
  booktitle = {Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  month     = jun,
  year      = {2019},
  address   = {Minneapolis, Minnesota},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/N19-1421/},
  doi       = {10.18653/v1/N19-1421},
  pages     = {4149--4158},
  abstract  = {When answering a question, people often draw upon their rich world knowledge in addition to the particular context. Recent work has focused primarily on answering questions given some relevant document or context, and required very little general background. To investigate question answering with prior knowledge, we present CommonsenseQA: a challenging new dataset for commonsense question answering. To capture common sense beyond associations, we extract from ConceptNet (Speer et al., 2017) multiple target concepts that have the same semantic relation to a single source concept. Crowd-workers are asked to author multiple-choice questions that mention the source concept and discriminate in turn between each of the target concepts. This encourages workers to create questions with complex semantics that often require prior knowledge. We create 12,247 questions through this procedure and demonstrate the difficulty of our task with a large number of strong baselines. Our best baseline is based on BERT-large (Devlin et al., 2018) and obtains 56{\%} accuracy, well below human performance, which is 89{\%}.}
}

@inproceedings{commonsense,
  title     = {Commonsense Reasoning for Natural Language Processing},
  author    = {Sap, Maarten  and
               Shwartz, Vered  and
               Bosselut, Antoine  and
               Choi, Yejin  and
               Roth, Dan},
  editor    = {Savary, Agata  and
               Zhang, Yue},
  booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts},
  month     = jul,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.acl-tutorials.7/},
  doi       = {10.18653/v1/2020.acl-tutorials.7},
  pages     = {27--33},
  abstract  = {Commonsense knowledge, such as knowing that {\textquotedblleft}bumping into people annoys them{\textquotedblright} or {\textquotedblleft}rain makes the road slippery{\textquotedblright}, helps humans navigate everyday situations seamlessly. Yet, endowing machines with such human-like commonsense reasoning capabilities has remained an elusive goal of artificial intelligence research for decades. In recent years, commonsense knowledge and reasoning have received renewed attention from the natural language processing (NLP) community, yielding exploratory studies in automated commonsense understanding. We organize this tutorial to provide researchers with the critical foundations and recent advances in commonsense representation and reasoning, in the hopes of casting a brighter light on this promising area of future research. In our tutorial, we will (1) outline the various types of commonsense (e.g., physical, social), and (2) discuss techniques to gather and represent commonsense knowledge, while highlighting the challenges specific to this type of knowledge (e.g., reporting bias). We will then (3) discuss the types of commonsense knowledge captured by modern NLP systems (e.g., large pretrained language models), and (4) present ways to measure systems' commonsense reasoning abilities. We will finish with (5) a discussion of various ways in which commonsense reasoning can be used to improve performance on NLP tasks, exemplified by an (6) interactive session on integrating commonsense into a downstream task.}
}

@misc{mishra2023lilaunifiedbenchmarkmathematical,
  title         = {Lila: A Unified Benchmark for Mathematical Reasoning},
  author        = {Swaroop Mishra and Matthew Finlayson and Pan Lu and Leonard Tang and Sean Welleck and Chitta Baral and Tanmay Rajpurohit and Oyvind Tafjord and Ashish Sabharwal and Peter Clark and Ashwin Kalyan},
  year          = {2023},
  eprint        = {2210.17517},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2210.17517}
}

@inproceedings{wang-lu-2023-learning,
  title     = {Learning Multi-Step Reasoning by Solving Arithmetic Tasks},
  author    = {Wang, Tianduo  and
               Lu, Wei},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-short.106/},
  doi       = {10.18653/v1/2023.acl-short.106},
  pages     = {1229--1238},
  abstract  = {Mathematical reasoning is regarded as a necessary ability for Language Models (LMs). Recent works demonstrate large LMs' impressive performance in solving math problems. The success is attributed to their Chain-of-Thought (CoT) reasoning abilities, i.e., the ability to decompose complex questions into step-by-step reasoning chains, but such ability seems only to emerge from models with abundant parameters. This work investigates how to incorporate relatively small LMs with the capabilities of multi-step reasoning. We propose to inject such abilities by continually pre-training LMs on a synthetic dataset MsAT which is composed of Multi-step Arithmetic Tasks. Our experiments on four math word problem datasets show the effectiveness of the proposed method in enhancing LMs' math reasoning abilities.}
}

@misc{mahowald2024dissociatinglanguagethoughtlarge,
  title         = {Dissociating language and thought in large language models},
  author        = {Kyle Mahowald and Anna A. Ivanova and Idan A. Blank and Nancy Kanwisher and Joshua B. Tenenbaum and Evelina Fedorenko},
  year          = {2024},
  eprint        = {2301.06627},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2301.06627}
}

@misc{li2023counterfactualreasoningtestinglanguage,
  title         = {Counterfactual reasoning: Testing language models' understanding of hypothetical scenarios},
  author        = {Jiaxuan Li and Lang Yu and Allyson Ettinger},
  year          = {2023},
  eprint        = {2305.16572},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2305.16572}
}

@misc{li2022counterfactualreasoninglanguagemodels,
  title         = {Counterfactual reasoning: Do language models need world knowledge for causal understanding?},
  author        = {Jiaxuan Li and Lang Yu and Allyson Ettinger},
  year          = {2022},
  eprint        = {2212.03278},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2212.03278}
}

@misc{analogical1,
  title         = {Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models},
  author        = {Martha Lewis and Melanie Mitchell},
  year          = {2024},
  eprint        = {2402.08955},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2402.08955}
}

@misc{analogical2,
  title         = {Can Large Language Models generalize analogy solving like people can?},
  author        = {Claire E. Stevenson and Alexandra Pafford and Han L. J. van der Maas and Melanie Mitchell},
  year          = {2025},
  eprint        = {2411.02348},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2411.02348}
}


@inproceedings{kondo-etal-2023-probing,
  title     = {Probing Physical Reasoning with Counter-Commonsense Context},
  author    = {Kondo, Kazushi  and
               Sugawara, Saku  and
               Aizawa, Akiko},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-short.53/},
  doi       = {10.18653/v1/2023.acl-short.53},
  pages     = {603--612},
  abstract  = {In this study, we create a CConS (Counter-commonsense Contextual Size comparison) dataset to investigate how physical commonsense affects the contextualized size comparison task; the proposed dataset consists of both contexts that fit physical commonsense and those that do not. This dataset tests the ability of language models to predict the size relationship between objects under various contexts generated from our curated noun list and templates. We measure the ability of several masked language models and encoder-decoder models. The results show that while large language models can use prepositions such as {\textquotedblleft}in{\textquotedblright} and {\textquotedblleft}into{\textquotedblright} in the provided context to infer size relationships, they fail to use verbs and thus make incorrect judgments led by their prior physical commonsense.}
}

@misc{yu2023ifqadatasetopendomainquestion,
  title         = {IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions},
  author        = {Wenhao Yu and Meng Jiang and Peter Clark and Ashish Sabharwal},
  year          = {2023},
  eprint        = {2305.14010},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2305.14010}
}

@inproceedings{adaptability,
  title     = {Challenging Large Language Models with New Tasks: A Study on their Adaptability and Robustness},
  author    = {Li, Chenxi  and
               Tian, Yuanhe  and
               Zerong, Zhaxi  and
               Song, Yan  and
               Xia, Fei},
  editor    = {Ku, Lun-Wei  and
               Martins, Andre  and
               Srikumar, Vivek},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2024},
  month     = aug,
  year      = {2024},
  address   = {Bangkok, Thailand},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.findings-acl.485/},
  doi       = {10.18653/v1/2024.findings-acl.485},
  pages     = {8140--8162},
  abstract  = {Recent progress in large language models (LLMs) has marked a notable milestone in the field of artificial intelligence. The conventional evaluation of LLMs primarily relies on existing tasks and benchmarks, raising concerns about test set contamination and the genuine comprehension abilities of LLMs. To address these concerns, we propose to evaluate LLMs by designing new tasks, automatically generating evaluation datasets for the tasks, and conducting detailed error analyses to scrutinize LLMs' adaptability to new tasks, their sensitivity to prompt variations, and their error tendencies. We investigate the capacity of LLMs to adapt to new but simple tasks, especially when they diverge from the models' pre-existing knowledge. Our methodology emphasizes the creation of straightforward tasks, facilitating a precise error analysis to uncover the underlying causes of LLM failures. This strategic approach also aims to uncover effective strategies for enhancing LLM performance based on the detailed error analysis of system output.}
}

@misc{ball2024countllmsfixedeffectfallacy,
  title         = {Can We Count on LLMs? The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities},
  author        = {Thomas Ball and Shuo Chen and Cormac Herley},
  year          = {2024},
  eprint        = {2409.07638},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2409.07638}
}

@misc{xie2025memorizationlargelanguagemodels,
  title         = {On Memorization of Large Language Models in Logical Reasoning},
  author        = {Chulin Xie and Yangsibo Huang and Chiyuan Zhang and Da Yu and Xinyun Chen and Bill Yuchen Lin and Bo Li and Badih Ghazi and Ravi Kumar},
  year          = {2025},
  eprint        = {2410.23123},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2410.23123}
}

@misc{wang2025generalizationvsmemorizationtracing,
  title         = {Generalization v.s. Memorization: Tracing Language Models' Capabilities Back to Pretraining Data},
  author        = {Xinyi Wang and Antonis Antoniades and Yanai Elazar and Alfonso Amayuelas and Alon Albalak and Kexun Zhang and William Yang Wang},
  year          = {2025},
  eprint        = {2407.14985},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2407.14985}
}

@misc{lou2024quantifyingincontextreasoningeffects,
  title         = {Quantifying In-Context Reasoning Effects and Memorization Effects in LLMs},
  author        = {Siyu Lou and Yuntian Chen and Xiaodan Liang and Liang Lin and Quanshi Zhang},
  year          = {2024},
  eprint        = {2405.11880},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2405.11880}
}

@misc{vaswani2023attentionneed,
  title         = {Attention Is All You Need},
  author        = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
  year          = {2023},
  eprint        = {1706.03762},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1706.03762}
}

@article{nlp,
  title     = {Natural language processing: state of the art, current trends and challenges},
  volume    = {82},
  issn      = {1573-7721},
  url       = {http://dx.doi.org/10.1007/s11042-022-13428-4},
  doi       = {10.1007/s11042-022-13428-4},
  number    = {3},
  journal   = {Multimedia Tools and Applications},
  publisher = {Springer Science and Business Media LLC},
  author    = {Khurana, Diksha and Koli, Aditya and Khatter, Kiran and Singh, Sukhdev},
  year      = {2022},
  month     = jul,
  pages     = {3713–3744}
}

@misc{llmsurvey,
  title         = {Large Language Models: A Survey},
  author        = {Shervin Minaee and Tomas Mikolov and Narjes Nikzad and Meysam Chenaghlu and Richard Socher and Xavier Amatriain and Jianfeng Gao},
  year          = {2025},
  eprint        = {2402.06196},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.06196}
}

@article{Sherstinsky_2020,
  title     = {Fundamentals of Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network},
  volume    = {404},
  issn      = {0167-2789},
  url       = {http://dx.doi.org/10.1016/j.physd.2019.132306},
  doi       = {10.1016/j.physd.2019.132306},
  journal   = {Physica D: Nonlinear Phenomena},
  publisher = {Elsevier BV},
  author    = {Sherstinsky, Alex},
  year      = {2020},
  month     = mar,
  pages     = {132306}
}

@misc{rnns,
  title         = {Recurrent Neural Networks (RNNs): A gentle Introduction and Overview},
  author        = {Robin M. Schmidt},
  year          = {2019},
  eprint        = {1912.05911},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1912.05911}
}

@misc{lstms,
  title         = {Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks},
  author        = {Ralf C. Staudemeyer and Eric Rothstein Morris},
  year          = {2019},
  eprint        = {1909.09586},
  archiveprefix = {arXiv},
  primaryclass  = {cs.NE},
  url           = {https://arxiv.org/abs/1909.09586}
}

@inproceedings{NIPS2000_728f206c,
  author    = {Bengio, Yoshua and Ducharme, R\'{e}jean and Vincent, Pascal},
  booktitle = {Advances in Neural Information Processing Systems},
  editor    = {T. Leen and T. Dietterich and V. Tresp},
  pages     = {},
  publisher = {MIT Press},
  title     = {A Neural Probabilistic Language Model},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2000/file/728f206c2a01bf572b5940d7d9a8fa4c-Paper.pdf},
  volume    = {13},
  year      = {2000}
}

@misc{byte,
  title         = {Neural Machine Translation of Rare Words with Subword Units},
  author        = {Rico Sennrich and Barry Haddow and Alexandra Birch},
  year          = {2016},
  eprint        = {1508.07909},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1508.07909}
}


@misc{uni,
  title         = {Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates},
  author        = {Taku Kudo},
  year          = {2018},
  eprint        = {1804.10959},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1804.10959}
}

@misc{word,
  title         = {Fast WordPiece Tokenization},
  author        = {Xinying Song and Alex Salcianu and Yang Song and Dave Dopson and Denny Zhou},
  year          = {2021},
  eprint        = {2012.15524},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2012.15524}
}

@misc{sentence,
  title         = {SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing},
  author        = {Taku Kudo and John Richardson},
  year          = {2018},
  eprint        = {1808.06226},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1808.06226}
}

@inproceedings{10.3115/992424.992434,
  author    = {Webster, Jonathan J. and Kit, Chunyu},
  title     = {Tokenization as the initial phase in NLP},
  year      = {1992},
  publisher = {Association for Computational Linguistics},
  address   = {USA},
  url       = {https://doi.org/10.3115/992424.992434},
  doi       = {10.3115/992424.992434},
  abstract  = {In this paper, the authors address the significance and complexity of tokenization, the beginning step of NLP. Notions of word and token are discussed and defined from the viewpoints of lexicography and pragmatic implementation, respectively. Automatic segmentation of Chinese words is presented as an illustration of tokenization. Practical approaches to identification of compound tokens in English, such as idioms, phrasal verbs and fixed expressions, are developed.},
  booktitle = {Proceedings of the 14th Conference on Computational Linguistics - Volume 4},
  pages     = {1106–1110},
  numpages  = {5},
  location  = {Nantes, France},
  series    = {COLING '92}
}

@article{article,
  author  = {Raiaan, Mohaimenul and Mukta, Saddam and Fatema, Kaniz and Fahad, Nur and Sakib, Sadman and Mim, Most. Marufatul Jannat and Ahmad, Jubaer and Ali, Mohammed Eunus and Azam, Sami},
  year    = {2024},
  month   = {01},
  pages   = {1-1},
  title   = {A Review on Large Language Models: Architectures, Applications, Taxonomies, Open Issues and Challenges},
  volume  = {PP},
  journal = {IEEE Access},
  doi     = {10.1109/ACCESS.2024.3365742}
}

@misc{llmoverview,
  title         = {A Comprehensive Overview of Large Language Models},
  author        = {Humza Naveed and Asad Ullah Khan and Shi Qiu and Muhammad Saqib and Saeed Anwar and Muhammad Usman and Naveed Akhtar and Nick Barnes and Ajmal Mian},
  year          = {2024},
  eprint        = {2307.06435},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2307.06435}
}

@misc{chowdhery2022palmscalinglanguagemodeling,
  title         = {PaLM: Scaling Language Modeling with Pathways},
  author        = {Aakanksha Chowdhery and Sharan Narang and Jacob Devlin and Maarten Bosma and Gaurav Mishra and Adam Roberts and Paul Barham and Hyung Won Chung and Charles Sutton and Sebastian Gehrmann and Parker Schuh and Kensen Shi and Sasha Tsvyashchenko and Joshua Maynez and Abhishek Rao and Parker Barnes and Yi Tay and Noam Shazeer and Vinodkumar Prabhakaran and Emily Reif and Nan Du and Ben Hutchinson and Reiner Pope and James Bradbury and Jacob Austin and Michael Isard and Guy Gur-Ari and Pengcheng Yin and Toju Duke and Anselm Levskaya and Sanjay Ghemawat and Sunipa Dev and Henryk Michalewski and Xavier Garcia and Vedant Misra and Kevin Robinson and Liam Fedus and Denny Zhou and Daphne Ippolito and David Luan and Hyeontaek Lim and Barret Zoph and Alexander Spiridonov and Ryan Sepassi and David Dohan and Shivani Agrawal and Mark Omernick and Andrew M. Dai and Thanumalayan Sankaranarayana Pillai and Marie Pellat and Aitor Lewkowycz and Erica Moreira and Rewon Child and Oleksandr Polozov and Katherine Lee and Zongwei Zhou and Xuezhi Wang and Brennan Saeta and Mark Diaz and Orhan Firat and Michele Catasta and Jason Wei and Kathy Meier-Hellstern and Douglas Eck and Jeff Dean and Slav Petrov and Noah Fiedel},
  year          = {2022},
  eprint        = {2204.02311},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2204.02311}
}

@misc{transferlearning,
  title         = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author        = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  year          = {2023},
  eprint        = {1910.10683},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1910.10683}
}

@misc{transferlearningsurvey,
  title         = {A Comprehensive Survey on Transfer Learning},
  author        = {Fuzhen Zhuang and Zhiyuan Qi and Keyu Duan and Dongbo Xi and Yongchun Zhu and Hengshu Zhu and Hui Xiong and Qing He},
  year          = {2020},
  eprint        = {1911.02685},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1911.02685}
}

@misc{instruction,
  title         = {Scaling Instruction-Finetuned Language Models},
  author        = {Hyung Won Chung and Le Hou and Shayne Longpre and Barret Zoph and Yi Tay and William Fedus and Yunxuan Li and Xuezhi Wang and Mostafa Dehghani and Siddhartha Brahma and Albert Webson and Shixiang Shane Gu and Zhuyun Dai and Mirac Suzgun and Xinyun Chen and Aakanksha Chowdhery and Alex Castro-Ros and Marie Pellat and Kevin Robinson and Dasha Valter and Sharan Narang and Gaurav Mishra and Adams Yu and Vincent Zhao and Yanping Huang and Andrew Dai and Hongkun Yu and Slav Petrov and Ed H. Chi and Jeff Dean and Jacob Devlin and Adam Roberts and Denny Zhou and Quoc V. Le and Jason Wei},
  year          = {2022},
  eprint        = {2210.11416},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2210.11416}
}

@misc{instructiontuninglargelanguage,
  title         = {Instruction Tuning for Large Language Models: A Survey},
  author        = {Shengyu Zhang and Linfeng Dong and Xiaoya Li and Sen Zhang and Xiaofei Sun and Shuhe Wang and Jiwei Li and Runyi Hu and Tianwei Zhang and Fei Wu and Guoyin Wang},
  year          = {2024},
  eprint        = {2308.10792},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2308.10792}
}

@misc{finetunedlanguagemodelszeroshot,
  title         = {Finetuned Language Models Are Zero-Shot Learners},
  author        = {Jason Wei and Maarten Bosma and Vincent Y. Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V. Le},
  year          = {2022},
  eprint        = {2109.01652},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2109.01652}
}

@misc{alignment,
  title         = {Training language models to follow instructions with human feedback},
  author        = {Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
  year          = {2022},
  eprint        = {2203.02155},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2203.02155}
}

@misc{rlhf,
  title         = {Fine-Tuning Language Models from Human Preferences},
  author        = {Daniel M. Ziegler and Nisan Stiennon and Jeffrey Wu and Tom B. Brown and Alec Radford and Dario Amodei and Paul Christiano and Geoffrey Irving},
  year          = {2020},
  eprint        = {1909.08593},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1909.08593}
}

@misc{surveylargelanguagemodels,
  title         = {A Survey of Large Language Models},
  author        = {Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
  year          = {2025},
  eprint        = {2303.18223},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.18223}
}

@article{parameters,
  author = {Drexl, Josef and Hilty, Reto},
  year   = {2019},
  month  = {01},
  pages  = {},
  title  = {Technical aspects of artificial intelligence: An understanding from an intellectual property law perspective}
}

@inproceedings{Radford2019LanguageMA,
  title  = {Language Models are Unsupervised Multitask Learners},
  author = {Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year   = {2019},
  url    = {https://api.semanticscholar.org/CorpusID:160025533}
}

@misc{hoffmann2022trainingcomputeoptimallargelanguage,
  title         = {Training Compute-Optimal Large Language Models},
  author        = {Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
  year          = {2022},
  eprint        = {2203.15556},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2203.15556}
}

@misc{llmsasjudgescomprehensivesurveyllmbased,
  title         = {LLMs-as-Judges: A Comprehensive Survey on LLM-based Evaluation Methods},
  author        = {Haitao Li and Qian Dong and Junjie Chen and Huixue Su and Yujia Zhou and Qingyao Ai and Ziyi Ye and Yiqun Liu},
  year          = {2024},
  eprint        = {2412.05579},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2412.05579}
}

@misc{zheng2023judgingllmasajudgemtbenchchatbot,
  title         = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
  author        = {Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric P. Xing and Hao Zhang and Joseph E. Gonzalez and Ion Stoica},
  year          = {2023},
  eprint        = {2306.05685},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2306.05685}
}

@misc{gu2025surveyllmasajudge,
  title         = {A Survey on LLM-as-a-Judge},
  author        = {Jiawei Gu and Xuhui Jiang and Zhichao Shi and Hexiang Tan and Xuehao Zhai and Chengjin Xu and Wei Li and Yinghan Shen and Shengjie Ma and Honghao Liu and Saizhuo Wang and Kun Zhang and Yuanzhuo Wang and Wen Gao and Lionel Ni and Jian Guo},
  year          = {2025},
  eprint        = {2411.15594},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2411.15594}
}

@misc{single-eval1,
  title         = {LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models},
  author        = {Yen-Ting Lin and Yun-Nung Chen},
  year          = {2023},
  eprint        = {2305.13711},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2305.13711}
}

@inproceedings{single-eval2,
  title     = {{G}-Eval: {NLG} Evaluation using Gpt-4 with Better Human Alignment},
  author    = {Liu, Yang  and
               Iter, Dan  and
               Xu, Yichong  and
               Wang, Shuohang  and
               Xu, Ruochen  and
               Zhu, Chenguang},
  editor    = {Bouamor, Houda  and
               Pino, Juan  and
               Bali, Kalika},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.emnlp-main.153/},
  doi       = {10.18653/v1/2023.emnlp-main.153},
  pages     = {2511--2522},
  abstract  = {The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference-based metrics, such as BLEU and ROUGE, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference-free metrics for NLG evaluation, which have the benefit of being applicable to new tasks that lack human references. However, these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators. In this work, we present G-Eval, a framework of using large language models with chain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of NLG outputs. We experiment with two generation tasks, text summarization and dialogue generation. We show that G-Eval with GPT-4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task, outperforming all previous methods by a large margin. We also propose analysis on the behavior of LLM-based evaluators, and highlight the potential concern of LLM-based evaluators having a bias towards the LLM-generated texts.}
}

@misc{single-eval3,
  title         = {TALEC: Teach Your LLM to Evaluate in Specific Domain with In-house Criteria by Criteria Division and Zero-shot Plus Few-shot},
  author        = {Kaiqi Zhang and Shuai Yuan and Honghan Zhao},
  year          = {2024},
  eprint        = {2407.10999},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2407.10999}
}

@misc{multi-eval1,
  title         = {ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate},
  author        = {Chi-Min Chan and Weize Chen and Yusheng Su and Jianxuan Yu and Wei Xue and Shanghang Zhang and Jie Fu and Zhiyuan Liu},
  year          = {2023},
  eprint        = {2308.07201},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2308.07201}
}

@misc{multi-eval2,
  title         = {PRE: A Peer Review Based Large Language Model Evaluator},
  author        = {Zhumin Chu and Qingyao Ai and Yiteng Tu and Haitao Li and Yiqun Liu},
  year          = {2024},
  eprint        = {2401.15641},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2401.15641}
}

@misc{multi-eval3,
  title         = {PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations},
  author        = {Ruosen Li and Teerth Patel and Xinya Du},
  year          = {2024},
  eprint        = {2307.02762},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2307.02762}
}

@misc{colab1,
  title         = {Exploring the Reliability of Large Language Models as Customized Evaluators for Diverse NLP Tasks},
  author        = {Qintong Li and Leyang Cui and Lingpeng Kong and Wei Bi},
  year          = {2025},
  eprint        = {2310.19740},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.19740}
}

@misc{colab2,
  title         = {Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences},
  author        = {Shreya Shankar and J. D. Zamfirescu-Pereira and Björn Hartmann and Aditya G. Parameswaran and Ian Arawjo},
  year          = {2024},
  eprint        = {2404.12272},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC},
  url           = {https://arxiv.org/abs/2404.12272}
}

@misc{pointwise1,
  title         = {Prometheus: Inducing Fine-grained Evaluation Capability in Language Models},
  author        = {Seungone Kim and Jamin Shin and Yejin Cho and Joel Jang and Shayne Longpre and Hwaran Lee and Sangdoo Yun and Seongjin Shin and Sungdong Kim and James Thorne and Minjoon Seo},
  year          = {2024},
  eprint        = {2310.08491},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.08491}
}

@misc{pointwise2,
  title         = {Learning Evaluation Models from Large Language Models for Sequence Generation},
  author        = {Chenglong Wang and Hang Zhou and Kaiyan Chang and Tongran Liu and Chunliang Zhang and Quan Du and Tong Xiao and Yue Zhang and Jingbo Zhu},
  year          = {2025},
  eprint        = {2308.04386},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2308.04386}
}

@misc{pointwise3,
  title         = {Self-Judge: Selective Instruction Following with Alignment Self-Evaluation},
  author        = {Hai Ye and Hwee Tou Ng},
  year          = {2024},
  eprint        = {2409.00935},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2409.00935}
}

@misc{pairwise1,
  title         = {CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution},
  author        = {Maosong Cao and Alexander Lam and Haodong Duan and Hongwei Liu and Songyang Zhang and Kai Chen},
  year          = {2024},
  eprint        = {2410.16256},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2410.16256}
}

@misc{pairwise2,
  title         = {FedEval-LLM: Federated Evaluation of Large Language Models on Downstream Tasks with Collective Wisdom},
  author        = {Yuanqin He and Yan Kang and Lixin Fan and Qiang Yang},
  year          = {2024},
  eprint        = {2404.12273},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2404.12273}
}

@inproceedings{listwise1,
  series     = {SIGIR 2024},
  title      = {A Setwise Approach for Effective and Highly Efficient Zero-shot Ranking with Large Language Models},
  url        = {http://dx.doi.org/10.1145/3626772.3657813},
  doi        = {10.1145/3626772.3657813},
  booktitle  = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  publisher  = {ACM},
  author     = {Zhuang, Shengyao and Zhuang, Honglei and Koopman, Bevan and Zuccon, Guido},
  year       = {2024},
  month      = jul,
  pages      = {38–47},
  collection = {SIGIR 2024}
}


@misc{listwise2,
  title         = {Consolidating Ranking and Relevance Predictions of Large Language Models through Post-Processing},
  author        = {Le Yan and Zhen Qin and Honglei Zhuang and Rolf Jagerman and Xuanhui Wang and Michael Bendersky and Harrie Oosterhuis},
  year          = {2024},
  eprint        = {2404.11791},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2404.11791}
}

@misc{listwise3,
  title         = {Large Language Models are Zero-Shot Rankers for Recommender Systems},
  author        = {Yupeng Hou and Junjie Zhang and Zihan Lin and Hongyu Lu and Ruobing Xie and Julian McAuley and Wayne Xin Zhao},
  year          = {2024},
  eprint        = {2305.08845},
  archiveprefix = {arXiv},
  primaryclass  = {cs.IR},
  url           = {https://arxiv.org/abs/2305.08845}
}

@misc{fluency1,
  title         = {SummEval: Re-evaluating Summarization Evaluation},
  author        = {Alexander R. Fabbri and Wojciech Kryściński and Bryan McCann and Caiming Xiong and Richard Socher and Dragomir Radev},
  year          = {2021},
  eprint        = {2007.12626},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2007.12626}
}

@inproceedings{fluency2,
  title     = {Of Human Criteria and Automatic Metrics: A Benchmark of the Evaluation of Story Generation},
  author    = {Chhun, Cyril  and
               Colombo, Pierre  and
               Suchanek, Fabian M.  and
               Clavel, Chlo{\'e}},
  editor    = {Calzolari, Nicoletta  and
               Huang, Chu-Ren  and
               Kim, Hansaem  and
               Pustejovsky, James  and
               Wanner, Leo  and
               Choi, Key-Sun  and
               Ryu, Pum-Mo  and
               Chen, Hsin-Hsi  and
               Donatelli, Lucia  and
               Ji, Heng  and
               Kurohashi, Sadao  and
               Paggio, Patrizia  and
               Xue, Nianwen  and
               Kim, Seokhwan  and
               Hahm, Younggyun  and
               He, Zhong  and
               Lee, Tony Kyungil  and
               Santus, Enrico  and
               Bond, Francis  and
               Na, Seung-Hoon},
  booktitle = {Proceedings of the 29th International Conference on Computational Linguistics},
  month     = oct,
  year      = {2022},
  address   = {Gyeongju, Republic of Korea},
  publisher = {International Committee on Computational Linguistics},
  url       = {https://aclanthology.org/2022.coling-1.509/},
  pages     = {5794--5836},
  abstract  = {Research on Automatic Story Generation (ASG) relies heavily on human and automatic evaluation. However, there is no consensus on which human evaluation criteria to use, and no analysis of how well automatic criteria correlate with them. In this paper, we propose to re-evaluate ASG evaluation. We introduce a set of 6 orthogonal and comprehensive human criteria, carefully motivated by the social sciences literature. We also present HANNA, an annotated dataset of 1,056 stories produced by 10 different ASG systems. HANNA allows us to quantitatively evaluate the correlations of 72 automatic metrics with human criteria. Our analysis highlights the weaknesses of current metrics for ASG and allows us to formulate practical recommendations for ASG evaluation.}
}

@misc{accuracy1,
  title         = {Evaluating Large Language Models Trained on Code},
  author        = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  year          = {2021},
  eprint        = {2107.03374},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2107.03374}
}

@misc{accuracy2,
  title         = {SWE-bench: Can Language Models Resolve Real-World GitHub Issues?},
  author        = {Carlos E. Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik Narasimhan},
  year          = {2024},
  eprint        = {2310.06770},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.06770}
}

@misc{task-specific1,
  title         = {JudgeBench: A Benchmark for Evaluating LLM-based Judges},
  author        = {Sijun Tan and Siyuan Zhuang and Kyle Montgomery and William Y. Tang and Alejandro Cuadron and Chenguang Wang and Raluca Ada Popa and Ion Stoica},
  year          = {2025},
  eprint        = {2410.12784},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2410.12784}
}

@misc{task-specific2,
  title         = {WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild},
  author        = {Bill Yuchen Lin and Yuntian Deng and Khyathi Chandu and Faeze Brahman and Abhilasha Ravichander and Valentina Pyatkin and Nouha Dziri and Ronan Le Bras and Yejin Choi},
  year          = {2024},
  eprint        = {2406.04770},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2406.04770}
}

@misc{task-specific3,
  title         = {PKU-SafeRLHF: Towards Multi-Level Safety Alignment for LLMs with Human Preference},
  author        = {Jiaming Ji and Donghai Hong and Borong Zhang and Boyuan Chen and Josef Dai and Boren Zheng and Tianyi Qiu and Boxun Li and Yaodong Yang},
  year          = {2024},
  eprint        = {2406.15513},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2406.15513}
}

@inproceedings{freitag-etal-2021-results,
  title     = {Results of the {WMT}21 Metrics Shared Task: Evaluating Metrics with Expert-based Human Evaluations on {TED} and News Domain},
  author    = {Freitag, Markus  and
               Rei, Ricardo  and
               Mathur, Nitika  and
               Lo, Chi-kiu  and
               Stewart, Craig  and
               Foster, George  and
               Lavie, Alon  and
               Bojar, Ond{\v{r}}ej},
  editor    = {Barrault, Loic  and
               Bojar, Ondrej  and
               Bougares, Fethi  and
               Chatterjee, Rajen  and
               Costa-jussa, Marta R.  and
               Federmann, Christian  and
               Fishel, Mark  and
               Fraser, Alexander  and
               Freitag, Markus  and
               Graham, Yvette  and
               Grundkiewicz, Roman  and
               Guzman, Paco  and
               Haddow, Barry  and
               Huck, Matthias  and
               Yepes, Antonio Jimeno  and
               Koehn, Philipp  and
               Kocmi, Tom  and
               Martins, Andre  and
               Morishita, Makoto  and
               Monz, Christof},
  booktitle = {Proceedings of the Sixth Conference on Machine Translation},
  month     = nov,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.wmt-1.73/},
  pages     = {733--774},
  abstract  = {This paper presents the results of the WMT21 Metrics Shared Task. Participants were asked to score the outputs of the translation systems competing in the WMT21 News Translation Task with automatic metrics on two different domains: news and TED talks. All metrics were evaluated on how well they correlate at the system- and segment-level with human ratings. Contrary to previous years' editions, this year we acquired our own human ratings based on expert-based human evaluation via Multidimensional Quality Metrics (MQM). This setup had several advantages: (i) expert-based evaluation has been shown to be more reliable, (ii) we were able to evaluate all metrics on two different domains using translations of the same MT systems, (iii) we added 5 additional translations coming from the same system during system development. In addition, we designed three challenge sets that evaluate the robustness of all automatic metrics. We present an extensive analysis on how well metrics perform on three language pairs: English to German, English to Russian and Chinese to English. We further show the impact of different reference translations on reference-based metrics and compare our expert-based MQM annotation with the DA scores acquired by WMT.}
}

@misc{ref-free1,
  title         = {SocREval: Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation},
  author        = {Hangfeng He and Hongming Zhang and Dan Roth},
  year          = {2024},
  eprint        = {2310.00074},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.00074}
}

@misc{ref-free2,
  title         = {OpinSummEval: Revisiting Automated Evaluation for Opinion Summarization},
  author        = {Yuchen Shen and Xiaojun Wan},
  year          = {2023},
  eprint        = {2310.18122},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.18122}
}

@misc{explanation1,
  title         = {Beyond Scalar Reward Model: Learning Generative Judge from Preference Data},
  author        = {Ziyi Ye and Xiangsheng Li and Qiuchi Li and Qingyao Ai and Yujia Zhou and Wei Shen and Dong Yan and Yiqun Liu},
  year          = {2024},
  eprint        = {2410.03742},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2410.03742}
}

@misc{explanation2,
  title         = {Improving Model Factuality with Fine-grained Critique-based Evaluator},
  author        = {Yiqing Xie and Wenxuan Zhou and Pradyot Prakash and Di Jin and Yuning Mao and Quintin Fettes and Arya Talebzadeh and Sinong Wang and Han Fang and Carolyn Rose and Daniel Fried and Hejia Zhang},
  year          = {2025},
  eprint        = {2410.18359},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2410.18359}
}

@misc{feedback1,
  title         = {Self-Refine: Iterative Refinement with Self-Feedback},
  author        = {Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark},
  year          = {2023},
  eprint        = {2303.17651},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.17651}
}

@misc{feedback2,
  title         = {Teaching Large Language Models to Self-Debug},
  author        = {Xinyun Chen and Maxwell Lin and Nathanael Schärli and Denny Zhou},
  year          = {2023},
  eprint        = {2304.05128},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2304.05128}
}

@inproceedings{bleu,
  title     = {{B}leu: a Method for Automatic Evaluation of Machine Translation},
  author    = {Papineni, Kishore  and
               Roukos, Salim  and
               Ward, Todd  and
               Zhu, Wei-Jing},
  editor    = {Isabelle, Pierre  and
               Charniak, Eugene  and
               Lin, Dekang},
  booktitle = {Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics},
  month     = jul,
  year      = {2002},
  address   = {Philadelphia, Pennsylvania, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/P02-1040/},
  doi       = {10.3115/1073083.1073135},
  pages     = {311--318}
}

@inproceedings{rouge,
  title     = {{ROUGE}: A Package for Automatic Evaluation of Summaries},
  author    = {Lin, Chin-Yew},
  booktitle = {Text Summarization Branches Out},
  month     = jul,
  year      = {2004},
  address   = {Barcelona, Spain},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W04-1013/},
  pages     = {74--81}
}

@inproceedings{meteor,
  title     = {{METEOR}: An Automatic Metric for {MT} Evaluation with Improved Correlation with Human Judgments},
  author    = {Banerjee, Satanjeev  and
               Lavie, Alon},
  editor    = {Goldstein, Jade  and
               Lavie, Alon  and
               Lin, Chin-Yew  and
               Voss, Clare},
  booktitle = {Proceedings of the {ACL} Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization},
  month     = jun,
  year      = {2005},
  address   = {Ann Arbor, Michigan},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/W05-0909/},
  pages     = {65--72}
}

@misc{hal1,
  title         = {A Survey of Hallucination in Large Foundation Models},
  author        = {Vipula Rawte and Amit Sheth and Amitava Das},
  year          = {2023},
  eprint        = {2309.05922},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2309.05922}
}      title={A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models}, 
      author={S. M Towhidul Islam Tonmoy and S M Mehedi Zaman and Vinija Jain and Anku Rani and Vipula Rawte and Aman Chadha and Amitava Das},
      year={2024},
      eprint={2401.01313},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.01313}, 
}

@misc{hal2,
  title         = {Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models},
  author        = {Yue Zhang and Yafu Li and Leyang Cui and Deng Cai and Lemao Liu and Tingchen Fu and Xinting Huang and Enbo Zhao and Yu Zhang and Yulong Chen and Longyue Wang and Anh Tuan Luu and Wei Bi and Freda Shi and Shuming Shi},
  year          = {2023},
  eprint        = {2309.01219},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2309.01219}
}

@article{bias,
  title     = {Bias and Fairness in Large Language Models: A Survey},
  author    = {Gallegos, Isabel O.  and
               Rossi, Ryan A.  and
               Barrow, Joe  and
               Tanjim, Md Mehrab  and
               Kim, Sungchul  and
               Dernoncourt, Franck  and
               Yu, Tong  and
               Zhang, Ruiyi  and
               Ahmed, Nesreen K.},
  journal   = {Computational Linguistics},
  volume    = {50},
  number    = {3},
  month     = sep,
  year      = {2024},
  address   = {Cambridge, MA},
  publisher = {MIT Press},
  url       = {https://aclanthology.org/2024.cl-3.8/},
  doi       = {10.1162/coli_a_00524},
  pages     = {1097--1179},
  abstract  = {Rapid advancements of large language models (LLMs) have enabled the processing, understanding, and generation of human-like text, with increasing integration into systems that touch our social sphere. Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this article, we present a comprehensive survey of bias evaluation and mitigation techniques for LLMs. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for LLMs. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely, metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Finally, we identify open problems and challenges for future work. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in LLMs.}
}

@misc{robust,
  title         = {PromptRobust: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts},
  author        = {Kaijie Zhu and Jindong Wang and Jiaheng Zhou and Zichen Wang and Hao Chen and Yidong Wang and Linyi Yang and Wei Ye and Yue Zhang and Neil Zhenqiang Gong and Xing Xie},
  year          = {2024},
  eprint        = {2306.04528},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2306.04528}
}

@misc{thakur2025judgingjudgesevaluatingalignment,
  title         = {Judging the Judges: Evaluating Alignment and Vulnerabilities in LLMs-as-Judges},
  author        = {Aman Singh Thakur and Kartik Choudhary and Venkat Srinik Ramayapally and Sankaran Vaidyanathan and Dieuwke Hupkes},
  year          = {2025},
  eprint        = {2406.12624},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2406.12624}
}

@misc{spearman1,
  title         = {Benchmarking Foundation Models with Language-Model-as-an-Examiner},
  author        = {Yushi Bai and Jiahao Ying and Yixin Cao and Xin Lv and Yuze He and Xiaozhi Wang and Jifan Yu and Kaisheng Zeng and Yijia Xiao and Haozhe Lyu and Jiayin Zhang and Juanzi Li and Lei Hou},
  year          = {2023},
  eprint        = {2306.04181},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2306.04181}
}

@misc{spearman2,
  title         = {Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators},
  author        = {Yinhong Liu and Han Zhou and Zhijiang Guo and Ehsan Shareghi and Ivan Vulić and Anna Korhonen and Nigel Collier},
  year          = {2025},
  eprint        = {2403.16950},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2403.16950}
}

@misc{pandalmautomaticevaluationbenchmark,
  title         = {PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization},
  author        = {Yidong Wang and Zhuohao Yu and Zhengran Zeng and Linyi Yang and Cunxiang Wang and Hao Chen and Chaoya Jiang and Rui Xie and Jindong Wang and Xing Xie and Wei Ye and Shikun Zhang and Yue Zhang},
  year          = {2024},
  eprint        = {2306.05087},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2306.05087}
}

@misc{judgelmfinetunedlargelanguage,
  title         = {JudgeLM: Fine-tuned Large Language Models are Scalable Judges},
  author        = {Lianghui Zhu and Xinggang Wang and Xinlong Wang},
  year          = {2025},
  eprint        = {2310.17631},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.17631}
}

@misc{code1,
  title         = {Evaluating Large Language Models Trained on Code},
  author        = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  year          = {2021},
  eprint        = {2107.03374},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2107.03374}
}

@misc{code2,
  title         = {SWE-bench: Can Language Models Resolve Real-World GitHub Issues?},
  author        = {Carlos E. Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik Narasimhan},
  year          = {2024},
  eprint        = {2310.06770},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.06770}
}

@misc{code3,
  title         = {Agent-as-a-Judge: Evaluate Agents with Agents},
  author        = {Mingchen Zhuge and Changsheng Zhao and Dylan Ashley and Wenyi Wang and Dmitrii Khizbullin and Yunyang Xiong and Zechun Liu and Ernie Chang and Raghuraman Krishnamoorthi and Yuandong Tian and Yangyang Shi and Vikas Chandra and Jürgen Schmidhuber},
  year          = {2024},
  eprint        = {2410.10934},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2410.10934}
}

@inproceedings{karpinska-iyyer-2023-large,
  title     = {Large Language Models Effectively Leverage Document-level Context for Literary Translation, but Critical Errors Persist},
  author    = {Karpinska, Marzena  and
               Iyyer, Mohit},
  editor    = {Koehn, Philipp  and
               Haddow, Barry  and
               Kocmi, Tom  and
               Monz, Christof},
  booktitle = {Proceedings of the Eighth Conference on Machine Translation},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.wmt-1.41/},
  doi       = {10.18653/v1/2023.wmt-1.41},
  pages     = {419--451},
  abstract  = {Large language models (LLMs) are competitive with the state of the art on a wide range of sentence-level translation datasets. However, their ability to translate paragraphs and documents remains unexplored because evaluation in these settings is costly and difficult. We show through a rigorous human evaluation that asking the GPT-3.5 (text-davinci-003) LLM to translate an entire literary paragraph (e.g., from a novel) at once results in higher-quality translations than standard sentence-by-sentence translation across 18 linguistically-diverse language pairs (e.g., translating into and out of Japanese, Polish, and English). Our evaluation, which took approximately 350 hours of effort for annotation and analysis, is conducted by hiring translators fluent in both the source and target language and asking them to provide both span-level error annotations as well as preference judgments of which system{'}s translations are better. We observe that discourse-level LLM translators commit fewer mistranslations, grammar errors, and stylistic inconsistencies than sentence-level approaches. With that said, critical errors still abound, including occasional content omissions, and a human translator{'}s intervention remains necessary to ensure that the author{'}s voice remains intact. We publicly release our dataset and error annotations to spur future research on the evaluation of document-level literary translation.}
}

@inproceedings{pagnoni-etal-2021-understanding,
  title     = {Understanding Factuality in Abstractive Summarization with {FRANK}: A Benchmark for Factuality Metrics},
  author    = {Pagnoni, Artidoro  and
               Balachandran, Vidhisha  and
               Tsvetkov, Yulia},
  editor    = {Toutanova, Kristina  and
               Rumshisky, Anna  and
               Zettlemoyer, Luke  and
               Hakkani-Tur, Dilek  and
               Beltagy, Iz  and
               Bethard, Steven  and
               Cotterell, Ryan  and
               Chakraborty, Tanmoy  and
               Zhou, Yichao},
  booktitle = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = jun,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.naacl-main.383/},
  doi       = {10.18653/v1/2021.naacl-main.383},
  pages     = {4812--4829},
  abstract  = {Modern summarization models generate highly fluent but often factually unreliable outputs. This motivated a surge of metrics attempting to measure the factuality of automatically generated summaries. Due to the lack of common benchmarks, these metrics cannot be compared. Moreover, all these methods treat factuality as a binary concept and fail to provide deeper insights on the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN/DM and XSum datasets. Through these annotations we identify the proportion of different categories of factual errors and benchmark factuality metrics, showing their correlation with human judgement as well as their specific strengths and weaknesses.}
}

@misc{dialogue,
  title         = {Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations},
  author        = {Karthik Gopalakrishnan and Behnam Hedayatnia and Qinlang Chen and Anna Gottardi and Sanjeev Kwatra and Anu Venkatesh and Raefer Gabriel and Dilek Hakkani-Tur},
  year          = {2023},
  eprint        = {2308.11995},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2308.11995}
}

@misc{mllm,
  title         = {MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark},
  author        = {Dongping Chen and Ruoxi Chen and Shilin Zhang and Yinuo Liu and Yaochen Wang and Huichi Zhou and Qihui Zhang and Yao Wan and Pan Zhou and Lichao Sun},
  year          = {2024},
  eprint        = {2402.04788},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.04788}
}

@misc{mmevalmultilingualmetaevaluationbenchmark,
  title         = {MM-Eval: A Multilingual Meta-Evaluation Benchmark for LLM-as-a-Judge and Reward Models},
  author        = {Guijin Son and Dongkeun Yoon and Juyoung Suk and Javier Aula-Blasco and Mano Aslan and Vu Trong Kim and Shayekh Bin Islam and Jaume Prats-Cristià and Lucía Tormo-Bañuelos and Seungone Kim},
  year          = {2025},
  eprint        = {2410.17578},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2410.17578}
}

@misc{story,
  title         = {Can Large Language Models Be an Alternative to Human Evaluations?},
  author        = {Cheng-Han Chiang and Hung-yi Lee},
  year          = {2023},
  eprint        = {2305.01937},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2305.01937}
}

@misc{sum,
  title         = {Is ChatGPT a Good NLG Evaluator? A Preliminary Study},
  author        = {Jiaan Wang and Yunlong Liang and Fandong Meng and Zengkui Sun and Haoxiang Shi and Zhixu Li and Jinan Xu and Jianfeng Qu and Jie Zhou},
  year          = {2023},
  eprint        = {2303.04048},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.04048}
}

@inproceedings{chen-etal-2024-humans,
  title     = {Humans or {LLM}s as the Judge? A Study on Judgement Bias},
  author    = {Chen, Guiming Hardy  and
               Chen, Shunian  and
               Liu, Ziche  and
               Jiang, Feng  and
               Wang, Benyou},
  editor    = {Al-Onaizan, Yaser  and
               Bansal, Mohit  and
               Chen, Yun-Nung},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.emnlp-main.474/},
  doi       = {10.18653/v1/2024.emnlp-main.474},
  pages     = {8301--8327},
  abstract  = {Adopting human and large language models (LLM) as judges (*a.k.a* human- and LLM-as-a-judge) for evaluating the performance of LLMs has recently gained attention. Nonetheless, this approach concurrently introduces potential biases from human and LLMs, questioning the reliability of the evaluation results. In this paper, we propose a novel framework that is free from referencing groundtruth annotations for investigating **Misinformation Oversight Bias**, **Gender Bias**, **Authority Bias** and **Beauty Bias** on LLM and human judges. We curate a dataset referring to the revised Bloom{'}s Taxonomy and conduct thousands of evaluations. Results show that human and LLM judges are vulnerable to perturbations to various degrees, and that even the cutting-edge judges possess considerable biases. We further exploit these biases to conduct attacks on LLM judges. We hope that our work can notify the community of the bias and vulnerability of human- and LLM-as-a-judge, as well as the urgency of developing robust evaluation systems.}
}

@misc{ver,
  title         = {JurEE not Judges: safeguarding llm interactions with small, specialised Encoder Ensembles},
  author        = {Dom Nasrabadi},
  year          = {2024},
  eprint        = {2410.08442},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2410.08442}
}

@misc{ye2024justiceprejudicequantifyingbiases,
  title         = {Justice or Prejudice? Quantifying Biases in LLM-as-a-Judge},
  author        = {Jiayi Ye and Yanbo Wang and Yue Huang and Dongping Chen and Qihui Zhang and Nuno Moniz and Tian Gao and Werner Geyer and Chao Huang and Pin-Yu Chen and Nitesh V Chawla and Xiangliang Zhang},
  year          = {2024},
  eprint        = {2410.02736},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2410.02736}
}

@misc{emergent,
  title         = {Emergent Abilities of Large Language Models},
  author        = {Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
  year          = {2022},
  eprint        = {2206.07682},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2206.07682}
}

@article{imitation,
  title   = {Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  author  = {Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adri{\`a} Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Andreassen and Andrea Madotto and An-743 drea Santilli and Andreas Stuhlm{\"u}ller and Andrew M. Dai and Andrew La and Andrew K. Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karakas and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bartlomiej Bojanowski and Batuhan {\"O}zyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Stephen Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and C{\`e}sar Ferri Ram{\'i}rez and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Christopher Callison-Burch and Christian Waites and Christian Voigt and Christopher D. Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Daniel H Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Mosegu{\'i} Gonz{\'a}lez and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodol{\`a} and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A. Chi and Ethan Dyer and Ethan J. Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Mart{\'i}nez-Plumed and Francesca Happ{\'e} and François Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germ{\'a}n Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Xinyue Wang and Gonzalo Jaimovitch-L{\'o}pez and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hanna Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Shevlin and Hinrich Sch{\"u}tze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and John Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fern{\'a}ndez Fisac and James B. Simon and James Koppel and James Zheng and James Zou and Jan Kocoń and Jana Thompson and Janelle Wingfield and Jared Kaplan and Jarema Radom and Jascha Narain Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Oluwadara Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Jane W Waweru and John Burden and John Miller and John U. Balis and Jonathan Batchelder and Jonathan Berant and Jorg Frohberg and Jos Rozen and Jos{\'e} Hern{\'a}ndez-Orallo and Joseph Boudeman and Joseph Guerr and Joseph Jones and Joshua B. Tenenbaum and Josh Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh D. Dhole and Kevin Gimpel and Kevin Omondi and Kory Wallace Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras Ochando and Louis-Philippe Morency and Luca Moschella and Luca Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros Col{\'o}n and Luke Metz and L{\"u}tfi Kerem Senel and Maarten Bosma and Maarten Sap and Maartje ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Mar{\'i}a Jos{\'e} Ram{\'i}rez-Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L. Leavitt and Matthias Hagen and M{\'a}ty{\'a}s Schubert and Medina Baitemirova and Melody Arnaud and Melvin McElrath and Michael A. Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Michal Swedrowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mitch Walker and Mohit Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and T. MukundVarma and Nanyun Peng and Nathan A. Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nicole Martinez and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and P. Milkowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramon Risco and Raphael Milliere and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan Le Bras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Ruslan Salakhutdinov and Ryan Chi and Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Samuel Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel S. Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi S. Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Bradley Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven T Piantadosi and Stuart M. Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsunori Hashimoto and Te-Lin Wu and Th{\'e}o Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Venkatesh Ramasesh and Vinay Uday Prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Yiding Hao and Yifu Chen and Yonatan Belinkov and Yufang Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
  journal = {Trans. Mach. Learn. Res.},
  year    = {2023},
  volume  = {2023},
  url     = {https://api.semanticscholar.org/CorpusID:271601672}
}

@inproceedings{incontextlearning,
  title     = {A Survey on In-context Learning},
  author    = {Dong, Qingxiu  and
               Li, Lei  and
               Dai, Damai  and
               Zheng, Ce  and
               Ma, Jingyuan  and
               Li, Rui  and
               Xia, Heming  and
               Xu, Jingjing  and
               Wu, Zhiyong  and
               Chang, Baobao  and
               Sun, Xu  and
               Li, Lei  and
               Sui, Zhifang},
  editor    = {Al-Onaizan, Yaser  and
               Bansal, Mohit  and
               Chen, Yun-Nung},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.emnlp-main.64/},
  doi       = {10.18653/v1/2024.emnlp-main.64},
  pages     = {1107--1128},
  abstract  = {With the increasing capabilities of large language models (LLMs), in-context learning (ICL) has emerged as a new paradigm for natural language processing (NLP), where LLMs make predictions based on contexts augmented with a few examples. It has been a significant trend to explore ICL to evaluate and extrapolate the ability of LLMs. In this paper, we aim to survey and summarize the progress and challenges of ICL. We first present a formal definition of ICL and clarify its correlation to related studies. Then, we organize and discuss advanced techniques, including training strategies, prompt designing strategies, and related analysis. Additionally, we explore various ICL application scenarios, such as data engineering and knowledge updating. Finally, we address the challenges of ICL and suggest potential directions for further research. We hope that our work can encourage more research on uncovering how ICL works and improving ICL.}
}

@inproceedings{incon,
  title     = {The Mystery of In-Context Learning: A Comprehensive Survey on Interpretation and Analysis},
  author    = {Zhou, Yuxiang  and
               Li, Jiazheng  and
               Xiang, Yanzheng  and
               Yan, Hanqi  and
               Gui, Lin  and
               He, Yulan},
  editor    = {Al-Onaizan, Yaser  and
               Bansal, Mohit  and
               Chen, Yun-Nung},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.emnlp-main.795/},
  doi       = {10.18653/v1/2024.emnlp-main.795},
  pages     = {14365--14378},
  abstract  = {Understanding in-context learning (ICL) capability that enables large language models (LLMs) to excel in proficiency through demonstration examples is of utmost importance. This importance stems not only from the better utilization of this capability across various tasks, but also from the proactive identification and mitigation of potential risks, including concerns regarding truthfulness, bias, and toxicity, that may arise alongside the capability. In this paper, we present a thorough survey on the interpretation and analysis of in-context learning. First, we provide a concise introduction to the background and definition of in-context learning. Then, we give an overview of advancements from two perspectives: 1) a theoretical perspective, emphasizing studies on mechanistic interpretability and delving into the mathematical foundations behind ICL; and 2) an empirical perspective, concerning studies that empirically analyze factors associated with ICL. We conclude by discussing open questions and the challenges encountered, and suggesting potential avenues for future research. We believe that our work establishes the basis for further exploration into the interpretation of in-context learning. To aid this effort, we have created a repository containing resources that will be continually updated.}
}

@misc{instructionfollowing,
  title         = {Large Language Model Instruction Following: A Survey of Progresses and Challenges},
  author        = {Renze Lou and Kai Zhang and Wenpeng Yin},
  year          = {2024},
  eprint        = {2303.10475},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.10475}
}

@misc{code_gen1,
  title         = {A Survey on Large Language Models for Code Generation},
  author        = {Juyong Jiang and Fan Wang and Jiasi Shen and Sungju Kim and Sunghun Kim},
  year          = {2024},
  eprint        = {2406.00515},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2406.00515}
}

@misc{code_gen2,
  title         = {Evaluating Large Language Models Trained on Code},
  author        = {Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
  year          = {2021},
  eprint        = {2107.03374},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2107.03374}
}

@inproceedings{puzzle,
  title     = {Puzzle Solving using Reasoning of Large Language Models: A Survey},
  author    = {Giadikiaroglou, Panagiotis  and
               Lymperaiou, Maria  and
               Filandrianos, Giorgos  and
               Stamou, Giorgos},
  editor    = {Al-Onaizan, Yaser  and
               Bansal, Mohit  and
               Chen, Yun-Nung},
  booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.emnlp-main.646/},
  doi       = {10.18653/v1/2024.emnlp-main.646},
  pages     = {11574--11591},
  abstract  = {Exploring the capabilities of Large Language Models (LLMs) in puzzle solving unveils critical insights into their potential and challenges in AI, marking a significant step towards understanding their applicability in complex reasoning tasks. This survey leverages a unique taxonomy{---}dividing puzzles into rule-based and rule-less categories{---}to critically assess LLMs through various methodologies, including prompting techniques, neuro-symbolic approaches, and fine-tuning. Through a critical review of relevant datasets and benchmarks, we assess LLMs' performance, identifying significant challenges in complex puzzle scenarios. Our findings highlight the disparity between LLM capabilities and human-like reasoning, particularly in those requiring advanced logical inference. The survey underscores the necessity for novel strategies and richer datasets to advance LLMs' puzzle-solving proficiency and contribute to AI{'}s logical reasoning and creative problem-solving advancements.}
}

@article{sum-benchmarking,
  title     = {Benchmarking Large Language Models for News Summarization},
  author    = {Zhang, Tianyi  and
               Ladhak, Faisal  and
               Durmus, Esin  and
               Liang, Percy  and
               McKeown, Kathleen  and
               Hashimoto, Tatsunori B.},
  journal   = {Transactions of the Association for Computational Linguistics},
  volume    = {12},
  year      = {2024},
  address   = {Cambridge, MA},
  publisher = {MIT Press},
  url       = {https://aclanthology.org/2024.tacl-1.3/},
  doi       = {10.1162/tacl_a_00632},
  pages     = {39--57},
  abstract  = {Large language models (LLMs) have shown promise for automatic summarization but the reasons behind their successes are poorly understood. By conducting a human evaluation on ten LLMs across different pretraining methods, prompts, and model scales, we make two important observations. First, we find instruction tuning, not model size, is the key to the LLM{'}s zero-shot summarization capability. Second, existing studies have been limited by low-quality references, leading to underestimates of human performance and lower few-shot and finetuning performance. To better evaluate LLMs, we perform human evaluation over high-quality summaries we collect from freelance writers. Despite major stylistic differences such as the amount of paraphrasing, we find that LLM summaries are judged to be on par with human written summaries.}
}

@misc{summarizationalmost,
  title         = {Summarization is (Almost) Dead},
  author        = {Xiao Pu and Mingqi Gao and Xiaojun Wan},
  year          = {2023},
  eprint        = {2309.09558},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2309.09558}
}

@inproceedings{translation1,
  title     = {Multilingual Machine Translation with Large Language Models: Empirical Results and Analysis},
  author    = {Zhu, Wenhao  and
               Liu, Hongyi  and
               Dong, Qingxiu  and
               Xu, Jingjing  and
               Huang, Shujian  and
               Kong, Lingpeng  and
               Chen, Jiajun  and
               Li, Lei},
  editor    = {Duh, Kevin  and
               Gomez, Helena  and
               Bethard, Steven},
  booktitle = {Findings of the Association for Computational Linguistics: NAACL 2024},
  month     = jun,
  year      = {2024},
  address   = {Mexico City, Mexico},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.findings-naacl.176/},
  doi       = {10.18653/v1/2024.findings-naacl.176},
  pages     = {2765--2781},
  abstract  = {Large language models (LLMs) have demonstrated remarkable potential in handling multilingual machine translation (MMT). In this paper, we systematically investigate the advantages and challenges of LLMs for MMT by answering two questions: 1) How well do LLMs perform in translating massive languages? 2) Which factors affect LLMs' performance in translation? We thoroughly evaluate eight popular LLMs, including ChatGPT and GPT-4. Our empirical results show that translation capabilities of LLMs are continually involving. GPT-4 has beat the strong supervised baseline NLLB in 40.91{\%} of translation directions but still faces a large gap towards the commercial translation system like Google Translate, especially on low-resource languages. Through further analysis, we discover that LLMs exhibit new working patterns when used for MMT. First, LLM can acquire translation ability in a resource-efficient way and generate moderate translation even on zero-resource languages. Second, instruction semantics can surprisingly be ignored when given in-context exemplars. Third, cross-lingual exemplars can provide better task guidance for low-resource translation than exemplars in the same language pairs. Code will be released at: https://github.com/NJUNLP/MMT-LLM.}
}

@inproceedings{translation2,
  title     = {Are Large Language Models State-of-the-art Quality Estimators for Machine Translation of User-generated Content?},
  author    = {Qian, Shenbin  and
               Orasan, Constantin  and
               Kanojia, Diptesh  and
               Do Carmo, F{\'e}lix},
  editor    = {Nakazawa, Toshiaki  and
               Goto, Isao},
  booktitle = {Proceedings of the Eleventh Workshop on Asian Translation (WAT 2024)},
  month     = nov,
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.wat-1.4/},
  doi       = {10.18653/v1/2024.wat-1.4},
  pages     = {45--55},
  abstract  = {This paper investigates whether large language models (LLMs) are state-of-the-art quality estimators for machine translation of user-generated content (UGC) that contains emotional expressions, without the use of reference translations. To achieve this, we employ an existing emotion-related dataset with human-annotated errors and calculate quality evaluation scores based on the Multi-dimensional Quality Metrics. We compare the accuracy of several LLMs with that of our fine-tuned baseline models, under in-context learning and parameter-efficient fine-tuning (PEFT) scenarios. We find that PEFT of LLMs leads to better performance in score prediction with human interpretable explanations than fine-tuned models. However, a manual analysis of LLM outputs reveals that they still have problems such as refusal to reply to a prompt and unstable output while evaluating machine translation of UGC.}
}

@misc{sentiment1,
  title         = {Large language models for aspect-based sentiment analysis},
  author        = {Paul F. Simmering and Paavo Huoviala},
  year          = {2023},
  eprint        = {2310.18025},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.18025}
}

@inproceedings{sentiment2,
  title     = {Sentiment Analysis in the Era of Large Language Models: A Reality Check},
  author    = {Zhang, Wenxuan  and
               Deng, Yue  and
               Liu, Bing  and
               Pan, Sinno  and
               Bing, Lidong},
  editor    = {Duh, Kevin  and
               Gomez, Helena  and
               Bethard, Steven},
  booktitle = {Findings of the Association for Computational Linguistics: NAACL 2024},
  month     = jun,
  year      = {2024},
  address   = {Mexico City, Mexico},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.findings-naacl.246/},
  doi       = {10.18653/v1/2024.findings-naacl.246},
  pages     = {3881--3906},
  abstract  = {Sentiment analysis (SA) has been a long-standing research area in natural language processing. With the recent advent of large language models (LLMs), there is great potential for their employment on SA problems. However, the extent to which current LLMs can be leveraged for different sentiment analysis tasks remains unclear. This paper aims to provide a comprehensive investigation into the capabilities of LLMs in performing various sentiment analysis tasks, from conventional sentiment classification to aspect-based sentiment analysis and multifaceted analysis of subjective texts. We evaluate performance across 13 tasks on 26 datasets and compare the results against small language models (SLMs) trained on domain-specific datasets. Our study reveals that while LLMs demonstrate satisfactory performance in simpler tasks, they lag behind in more complex tasks requiring a deeper understanding of specific sentiment phenomena or structured sentiment information. However, LLMs significantly outperform SLMs in few-shot learning settings, suggesting their potential when annotation resources are limited. We also highlight the limitations of current evaluation practices in assessing LLMs' SA abilities and propose a novel benchmark, SentiEval, for a more comprehensive and realistic evaluation. Data and code are available at \url{https://github.com/DAMO-NLP-SG/LLM-Sentiment}.}
}

@misc{textclassification,
  title         = {Adaptable and Reliable Text Classification using Large Language Models},
  author        = {Zhiqiang Wang and Yiran Pang and Yanbin Lin and Xingquan Zhu},
  year          = {2024},
  eprint        = {2405.10523},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2405.10523}
}

@misc{largelanguagemodelstext,
  title         = {Large Language Models For Text Classification: Case Study And Comprehensive Review},
  author        = {Arina Kostina and Marios D. Dikaiakos and Dimosthenis Stefanidis and George Pallis},
  year          = {2025},
  eprint        = {2501.08457},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2501.08457}
}

@misc{largelanguagemodelszeroshottext,
  title         = {Large Language Models Are Zero-Shot Text Classifiers},
  author        = {Zhiqiang Wang and Yiran Pang and Yanbin Lin},
  year          = {2023},
  eprint        = {2312.01044},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2312.01044}
}

@inproceedings{qa1,
  title     = {Evaluating Open-Domain Question Answering in the Era of Large Language Models},
  author    = {Kamalloo, Ehsan  and
               Dziri, Nouha  and
               Clarke, Charles  and
               Rafiei, Davood},
  editor    = {Rogers, Anna  and
               Boyd-Graber, Jordan  and
               Okazaki, Naoaki},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2023},
  address   = {Toronto, Canada},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.acl-long.307/},
  doi       = {10.18653/v1/2023.acl-long.307},
  pages     = {5591--5606},
  abstract  = {Lexical matching remains the de facto evaluation method for open-domain question answering (QA). Unfortunately, lexical matching fails completely when a plausible candidate answer does not appear in the list of gold answers, which is increasingly the case as we shift from extractive to generative models. The recent success of large language models (LLMs) for QA aggravates lexical matching failures since candidate answers become longer, thereby making matching with the gold answers even more challenging. Without accurate evaluation, the true progress in open-domain QA remains unknown. In this paper, we conduct a thorough analysis of various open-domain QA models, including LLMs, by manually evaluating their answers on a subset of NQ-open, a popular benchmark. Our assessments reveal that while the true performance of all models is significantly underestimated, the performance of the InstructGPT (zero-shot) LLM increases by nearly +60{\%}, making it on par with existing top models, and the InstructGPT (few-shot) model actually achieves a new state-of-the-art on NQ-open. We also find that more than 50{\%} of lexical matching failures are attributed to semantically equivalent answers. We further demonstrate that regex matching ranks QA models consistent with human judgments, although still suffering from unnecessary strictness. Finally, we demonstrate that automated evaluation models are a reasonable surrogate for lexical matching in some circumstances, but not for long-form answers generated by LLMs. The automated models struggle in detecting hallucinations in LLM answers and are thus unable to evaluate LLMs. At this time, there appears to be no substitute for human evaluation.}
}


@misc{qa2,
  title         = {Question: How do Large Language Models perform on the Question Answering tasks? Answer:},
  author        = {Kevin Fischer and Darren Fürst and Sebastian Steindl and Jakob Lindner and Ulrich Schäfer},
  year          = {2024},
  eprint        = {2412.12893},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2412.12893}
}


@misc{kb1,
  title         = {Can Language Models Act as Knowledge Bases at Scale?},
  author        = {Qiyuan He and Yizhong Wang and Wenya Wang},
  year          = {2024},
  eprint        = {2402.14273},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.14273}
}

@misc{kb2,
  title         = {A Review on Language Models as Knowledge Bases},
  author        = {Badr AlKhamissi and Millicent Li and Asli Celikyilmaz and Mona Diab and Marjan Ghazvininejad},
  year          = {2022},
  eprint        = {2204.06031},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2204.06031}
}

@misc{agent1,
  title         = {Navigating Complexity: Orchestrated Problem Solving with Multi-Agent LLMs},
  author        = {Sumedh Rasal and E. J. Hauer},
  year          = {2024},
  eprint        = {2402.16713},
  archiveprefix = {arXiv},
  primaryclass  = {cs.MA},
  url           = {https://arxiv.org/abs/2402.16713}
}

@misc{agent2,
  title         = {Multi-Agent Collaboration Mechanisms: A Survey of LLMs},
  author        = {Khanh-Tung Tran and Dung Dao and Minh-Duong Nguyen and Quoc-Viet Pham and Barry O'Sullivan and Hoang D. Nguyen},
  year          = {2025},
  eprint        = {2501.06322},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2501.06322}
}

@misc{agent3,
  title         = {Large Language Model based Multi-Agents: A Survey of Progress and Challenges},
  author        = {Taicheng Guo and Xiuying Chen and Yaqi Wang and Ruidi Chang and Shichao Pei and Nitesh V. Chawla and Olaf Wiest and Xiangliang Zhang},
  year          = {2024},
  eprint        = {2402.01680},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.01680}
}

@misc{modal1,
  title         = {MM-LLMs: Recent Advances in MultiModal Large Language Models},
  author        = {Duzhen Zhang and Yahan Yu and Jiahua Dong and Chenxing Li and Dan Su and Chenhui Chu and Dong Yu},
  year          = {2024},
  eprint        = {2401.13601},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2401.13601}
}

@misc{modal2,
  title         = {A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks},
  author        = {Jiaqi Wang and Hanqi Jiang and Yiheng Liu and Chong Ma and Xu Zhang and Yi Pan and Mengyuan Liu and Peiran Gu and Sichen Xia and Wenjun Li and Yutong Zhang and Zihao Wu and Zhengliang Liu and Tianyang Zhong and Bao Ge and Tuo Zhang and Ning Qiang and Xintao Hu and Xi Jiang and Xin Zhang and Wei Zhang and Dinggang Shen and Tianming Liu and Shu Zhang},
  year          = {2024},
  eprint        = {2408.01319},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2408.01319}
}



@inproceedings{comp,
  title     = {Skills-in-Context: Unlocking Compositionality in Large Language Models},
  author    = {Chen, Jiaao  and
               Pan, Xiaoman  and
               Yu, Dian  and
               Song, Kaiqiang  and
               Wang, Xiaoyang  and
               Yu, Dong  and
               Chen, Jianshu},
  editor    = {Al-Onaizan, Yaser  and
               Bansal, Mohit  and
               Chen, Yun-Nung},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2024},
  month     = nov,
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.findings-emnlp.812/},
  doi       = {10.18653/v1/2024.findings-emnlp.812},
  pages     = {13838--13890},
  abstract  = {We investigate how to elicit compositional generalization capabilities in large language models (LLMs). Compositional generalization empowers LLMs to solve complex problems by combining foundational skills, a critical reasoning ability akin to human intelligence. However, even the most advanced LLMs currently struggle with this form of reasoning. We examine this problem within the framework of in-context learning and find that demonstrating both foundational skills and compositional examples grounded in these skills within the same prompt context is crucial. We refer to this prompt structure as skills-in-context (SKiC). With as few as two exemplars, this in-context learning structure enables LLMs to tackle more challenging problems requiring innovative skill combinations, achieving near-perfect systematic generalization across a broad range of tasks. Intriguingly, SKiC also unlocks the latent potential of LLMs, allowing them to more actively utilize pre-existing internal skills acquired during earlier pretraining stages to solve complex reasoning problems. The SKiC structure is robust across different skill constructions and exemplar choices and demonstrates strong transferability to new tasks. Finally, inspired by our in-context learning study, we show that fine-tuning LLMs with SKiC-style data can elicit zero-shot weak-to-strong generalization, enabling the models to solve much harder problems directly with standard prompting.}
}

@misc{stringli2025pitfallsscaleinvestigatinginverse,
  title         = {Pitfalls of Scale: Investigating the Inverse Task of Redefinition in Large Language Models},
  author        = {Elena Stringli and Maria Lymperaiou and Giorgos Filandrianos and Athanasios Voulodimos and Giorgos Stamou},
  year          = {2025},
  eprint        = {2502.12821},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2502.12821}
}

@misc{raptopoulos2025paktonmultiagentframeworkquestion,
  title         = {PAKTON: A Multi-Agent Framework for Question Answering in Long Legal Agreements},
  author        = {Petros Raptopoulos and Giorgos Filandrianos and Maria Lymperaiou and Giorgos Stamou},
  year          = {2025},
  eprint        = {2506.00608},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2506.00608}
}

@unknown{mushroom,
  author = {Vazquez, Raul and Mickus, Timothee and Zosa, Elaine and Vahtola, Teemu and Tiedemann, Jörg and Sinha, Aman and Segonne, Vincent and Sánchez-Vega, Fernando and Raganato, Alessandro and Libovický, Jindřich and Karlgren, Jussi and Ji, Shaoxiong and Helcl, Jindřich and Guillou, Liane and de Gibert Bonet, Ona and Bengoetxea, Jaione and Attieh, Joseph and Apidianaki, Marianna},
  year   = {2025},
  month  = {04},
  pages  = {},
  title  = {SemEval-2025 Task 3: Mu-SHROOM, the Multilingual Shared Task on Hallucinations and Related Observable Overgeneration Mistakes},
  doi    = {10.48550/arXiv.2504.11975}
}

@inproceedings{panagiotopoulos-etal-2025-riscore,
  title     = {{RISCORE}: Enhancing In-Context Riddle Solving in Language Models through Context-Reconstructed Example Augmentation},
  author    = {Panagiotopoulos, Ioannis  and
               Filandrianos, George  and
               Lymperaiou, Maria  and
               Stamou, Giorgos},
  editor    = {Rambow, Owen  and
               Wanner, Leo  and
               Apidianaki, Marianna  and
               Al-Khalifa, Hend  and
               Eugenio, Barbara Di  and
               Schockaert, Steven},
  booktitle = {Proceedings of the 31st International Conference on Computational Linguistics},
  month     = jan,
  year      = {2025},
  address   = {Abu Dhabi, UAE},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.coling-main.633/},
  pages     = {9431--9455},
  abstract  = {Riddle-solving requires advanced reasoning skills, pushing Large Language Models (LLMs) to engage in abstract thinking and creative problem-solving, often revealing limitations in their cognitive abilities. In this paper, we examine the riddle-solving capabilities of LLMs using a multiple-choice format, exploring how different prompting techniques impact performance on riddles that demand diverse reasoning skills. To enhance results, we introduce RISCORE (RIddle Solving with COntext REcontruciton) a novel fully automated prompting method that generates and utilizes contextually reconstructed sentence-based puzzles in conjunction with the original examples to create few-shot exemplars. Our experiments demonstrate that RISCORE significantly improves the performance of language models in both vertical and lateral thinking tasks, surpassing traditional exemplar selection strategies across a variety of few-shot settings.}
}

@inproceedings{thomas-etal-2024-never,
  title     = {``{I} Never Said That'': A dataset, taxonomy and baselines on response clarity classification},
  author    = {Thomas, Konstantinos  and
               Filandrianos, Giorgos  and
               Lymperaiou, Maria  and
               Zerva, Chrysoula  and
               Stamou, Giorgos},
  editor    = {Al-Onaizan, Yaser  and
               Bansal, Mohit  and
               Chen, Yun-Nung},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2024},
  month     = nov,
  year      = {2024},
  address   = {Miami, Florida, USA},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.findings-emnlp.300/},
  doi       = {10.18653/v1/2024.findings-emnlp.300},
  pages     = {5204--5233},
  abstract  = {Equivocation and ambiguity in public speech are well-studied discourse phenomena, especially in political science and analysis of political interviews. Inspired by the well-grounded theory on equivocation, we aim to resolve the closely related problem of response clarity in questions extracted from political interviews, leveraging the capabilities of Large Language Models (LLMs) and human expertise. To this end, we introduce a novel taxonomy that frames the task of detecting and classifying response clarity and a corresponding clarity classification dataset which consists of question-answer (QA) pairs drawn from political interviews and annotated accordingly. Our proposed two-level taxonomy addresses the clarity of a response in terms of the information provided for a given question (high-level) and also provides a fine-grained taxonomy of evasion techniques that relate to unclear, ambiguous responses (lower-level). We combine ChatGPT and human annotators to collect, validate and annotate discrete QA pairs from political interviews, to be used for our newly introduced response clarity task. We provide a detailed analysis and conduct several experiments with different model architectures, sizes and adaptation methods to gain insights and establish new baselines over the proposed dataset and task.}
}

@misc{kritharoula2023languagemodelsknowledgebases,
  title         = {Language Models as Knowledge Bases for Visual Word Sense Disambiguation},
  author        = {Anastasia Kritharoula and Maria Lymperaiou and Giorgos Stamou},
  year          = {2023},
  eprint        = {2310.01960},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2310.01960}
}

@misc{filandrianos2025biasbewareimpactcognitive,
  title         = {Bias Beware: The Impact of Cognitive Biases on LLM-Driven Product Recommendations},
  author        = {Giorgos Filandrianos and Angeliki Dimitriou and Maria Lymperaiou and Konstantinos Thomas and Giorgos Stamou},
  year          = {2025},
  eprint        = {2502.01349},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2502.01349}
}

@misc{evangelatos2025ailsntuasemeval2025task8,
  title         = {AILS-NTUA at SemEval-2025 Task 8: Language-to-Code prompting and Error Fixing for Tabular Question Answering},
  author        = {Andreas Evangelatos and Giorgos Filandrianos and Maria Lymperaiou and Athanasios Voulodimos and Giorgos Stamou},
  year          = {2025},
  eprint        = {2503.00435},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2503.00435}
}

@inproceedings{kritharoula-etal-2023-large,
  title     = {Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation},
  author    = {Kritharoula, Anastasia  and
               Lymperaiou, Maria  and
               Stamou, Giorgos},
  editor    = {Bouamor, Houda  and
               Pino, Juan  and
               Bali, Kalika},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.emnlp-main.807/},
  doi       = {10.18653/v1/2023.emnlp-main.807},
  pages     = {13053--13077},
  abstract  = {Visual Word Sense Disambiguation (VWSD) is a novel challenging task with the goal of retrieving an image among a set of candidates, which better represents the meaning of an ambiguous word within a given context. In this paper, we make a substantial step towards unveiling this interesting task by applying a varying set of approaches. Since VWSD is primarily a text-image retrieval task, we explore the latest transformer-based methods for multimodal retrieval. Additionally, we utilize Large Language Models (LLMs) as knowledge bases to enhance the given phrases and resolve ambiguity related to the target word. We also study VWSD as a unimodal problem by converting to text-to-text and image-to-image retrieval, as well as question-answering (QA), to fully explore the capabilities of relevant models. To tap into the implicit knowledge of LLMs, we experiment with Chain-of-Thought (CoT) prompting to guide explainable answer generation. On top of all, we train a learn to rank (LTR) model in order to combine our different modules, achieving competitive ranking results. Extensive experiments on VWSD demonstrate valuable insights to effectively drive future directions.}
}

@inproceedings{10.1007/978-3-031-91569-7_18,
  author    = {Argyrou, Georgia
               and Dimitriou, Angeliki
               and Lymperaiou, Maria
               and Filandrianos, Giorgos
               and Stamou, Giorgos},
  editor    = {Del Bue, Alessio
               and Canton, Cristian
               and Pont-Tuset, Jordi
               and Tommasi, Tatiana},
  title     = {Automatic Generation of Fashion Images Using Prompting in Generative Machine Learning Models},
  booktitle = {Computer Vision -- ECCV 2024 Workshops},
  year      = {2025},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {286--302},
  abstract  = {The advent of artificial intelligence has contributed in a groundbreaking transformation of the fashion industry, redefining creativity and innovation in unprecedented ways. This work investigates methodologies for generating tailored fashion descriptions using two distinct Large Language Models and a Stable Diffusion model for fashion image creation. Emphasizing adaptability in AI-driven fashion creativity, we depart from traditional approaches and focus on prompting techniques, such as zero-shot and few-shot learning, as well as Chain-of-Thought (CoT), which results in a variety of colors and textures, enhancing the diversity of the outputs. Central to our methodology is Retrieval-Augmented Generation (RAG), enriching models with insights from fashion sources to ensure contemporary representations. Evaluation combines quantitative metrics such as CLIPscore with qualitative human judgment, highlighting strengths in creativity, coherence, and aesthetic appeal across diverse styles. Among the participants, RAG and few-shot learning techniques are preferred for their ability to produce more relevant and appealing fashion descriptions. Our code is provided at https://github.com/georgiarg/AutoFashion.},
  isbn      = {978-3-031-91569-7}
}
@article{liu2024conspemollm,
  title   = {ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large Language Model},
  author  = {Liu, Zhiwei and Liu, Boyang and Thompson, Paul and Yang, Kailai and Ananiadou, Sophia},
  journal = {arXiv preprint arXiv:2403.06765},
  year    = {2024}
}

@article{liu2025conspemollmv2,
  title   = {ConspEmoLLM-v2: A robust and stable model to detect sentiment-transformed conspiracy theories},
  author  = {Liu, Zhiwei and Thompson, Paul and Rong, Jiaqi and Ananiadou, Sophia},
  journal = {arXiv preprint arXiv:2505.14917},
  year    = {2025}
}


@article{reducing,
  author  = {Thomas H. Costello  and Gordon Pennycook  and David G. Rand },
  title   = {Durably reducing conspiracy beliefs through dialogues with AI},
  journal = {Science},
  volume  = {385},
  number  = {6714},
  pages   = {eadq1814},
  year    = {2024},
  doi     = {10.1126/science.adq1814},
  url     = {https://www.science.org/doi/abs/10.1126/science.adq1814},
  eprint  = {https://www.science.org/doi/pdf/10.1126/science.adq1814}
}

@misc{costello2026largelanguagemodelseffectively,
  title         = {Large language models can effectively convince people to believe conspiracies},
  author        = {Thomas H. Costello and Kellin Pelrine and Matthew Kowal and Antonio A. Arechar and Jean-François Godbout and Adam Gleave and David Rand and Gordon Pennycook},
  year          = {2026},
  eprint        = {2601.05050},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2601.05050}
}

@article{just-the-facts,
  author  = {Costello, Thomas and Pennycook, Gordon and Rand, David},
  year    = {2025},
  month   = {02},
  pages   = {},
  title   = {Just the Facts: How Dialogues with AI Reduce Conspiracy Beliefs},
  journal = {PsyArXiv},
  doi     = {10.31234/osf.io/h7n8u_v1}
}

@misc{rani2025dialoguesaireducebeliefs,
  title         = {Dialogues with AI Reduce Beliefs in Misinformation but Build No Lasting Discernment Skills},
  author        = {Anku Rani and Valdemar Danry and Paul Pu Liang and Andrew B. Lippman and Pattie Maes},
  year          = {2025},
  eprint        = {2510.01537},
  archiveprefix = {arXiv},
  primaryclass  = {cs.HC},
  url           = {https://arxiv.org/abs/2510.01537}
}

% psychology
@article{psychology-of-conspiracy,
  author  = {Karen M. Douglas and Robbie M. Sutton and Aleksandra Cichocka},
  title   = {The Psychology of Conspiracy Theories},
  journal = {Current Directions in Psychological Science},
  volume  = {26},
  number  = {6},
  pages   = {538-542},
  year    = {2017},
  doi     = {10.1177/0963721417718261},
  note    = {PMID: 29276345},
  url     = {https://doi.org/10.1177/0963721417718261},
  eprint  = {https://doi.org/10.1177/0963721417718261}
}

@article{understanding,
  author   = {Douglas, Karen M. and Uscinski, Joseph E. and Sutton, Robbie M. and Cichocka, Aleksandra and Nefes, Turkay and Ang, Chee Siang and Deravi, Farzin},
  title    = {Understanding Conspiracy Theories},
  journal  = {Political Psychology},
  volume   = {40},
  number   = {S1},
  pages    = {3-35},
  keywords = {communication, conspiracy belief, conspiracy theories, politics, psychology},
  doi      = {https://doi.org/10.1111/pops.12568},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1111/pops.12568},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/pops.12568},
  year     = {2019}
}

@article{belief,
  author   = {van Prooijen, Jan-Willem and Douglas, Karen M.},
  title    = {Belief in conspiracy theories: Basic principles of an emerging research domain},
  journal  = {European Journal of Social Psychology},
  volume   = {48},
  number   = {7},
  pages    = {897-908},
  keywords = {conspiracy theories, consequences, universal, emotions, intergroup conflict},
  doi      = {https://doi.org/10.1002/ejsp.2530},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2530},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/ejsp.2530},
  year     = {2018}
}

@article{brotherton2013generic,
  title   = {Measuring Belief in Conspiracy Theories: The Generic Conspiracist Beliefs Scale},
  author  = {Brotherton, Robert and French, Christopher C. and Pickering, Andrew D.},
  journal = {Frontiers in Psychology},
  volume  = {4},
  pages   = {279},
  year    = {2013},
  doi     = {10.3389/fpsyg.2013.00279},
  url     = {https://doi.org/10.3389/fpsyg.2013.00279}
}

@inproceedings{filandrianos-etal-2025-bias,
  title     = {Bias Beware: The Impact of Cognitive Biases on {LLM}-Driven Product Recommendations},
  author    = {Filandrianos, Giorgos  and
               Dimitriou, Angeliki  and
               Lymperaiou, Maria  and
               Thomas, Konstantinos  and
               Stamou, Giorgos},
  editor    = {Christodoulopoulos, Christos  and
               Chakraborty, Tanmoy  and
               Rose, Carolyn  and
               Peng, Violet},
  booktitle = {Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  month     = nov,
  year      = {2025},
  address   = {Suzhou, China},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.emnlp-main.1140/},
  doi       = {10.18653/v1/2025.emnlp-main.1140},
  pages     = {22397--22426},
  isbn      = {979-8-89176-332-6}
}

@inproceedings{xu-etal-2024-earth,
  title     = {The Earth is Flat because...: Investigating {LLM}s' Belief towards Misinformation via Persuasive Conversation},
  author    = {Xu, Rongwu  and
               Lin, Brian  and
               Yang, Shujian  and
               Zhang, Tianqi  and
               Shi, Weiyan  and
               Zhang, Tianwei  and
               Fang, Zhixuan  and
               Xu, Wei  and
               Qiu, Han},
  editor    = {Ku, Lun-Wei  and
               Martins, Andre  and
               Srikumar, Vivek},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = aug,
  year      = {2024},
  address   = {Bangkok, Thailand},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.acl-long.858/},
  doi       = {10.18653/v1/2024.acl-long.858},
  pages     = {16259--16303}
}

@article{chen2024combatingmisinformation,
  author  = {Chen, Canyu and Shu, Kai},
  title   = {Combating misinformation in the age of LLMs: Opportunities and challenges},
  journal = {AI Magazine},
  year    = {2024},
  doi     = {10.1002/aaai.12188},
  url     = {https://doi.org/10.1002/aaai.12188}
}

% linguistic
@article{miani2022loco,
  title   = {LOCO: The 88-Million-Word Language of Conspiracy Corpus},
  author  = {Miani, Alessandro and Hills, Thomas and Bangerter, Adrian},
  journal = {Behavior Research Methods},
  volume  = {54},
  number  = {4},
  pages   = {1794--1817},
  year    = {2022},
  month   = aug,
  doi     = {10.3758/s13428-021-01698-z},
  url     = {https://doi.org/10.3758/s13428-021-01698-z},
  note    = {Epub 2021 Oct 25}
}

@inproceedings{mompelat-etal-2022-loco,
  title     = {How ``Loco'' Is the {LOCO} Corpus? Annotating the Language of Conspiracy Theories},
  author    = {Mompelat, Ludovic  and
               Tian, Zuoyu  and
               Kessler, Amanda  and
               Luettgen, Matthew  and
               Rajanala, Aaryana  and
               K{\"u}bler, Sandra  and
               Seelig, Michelle},
  editor    = {Pradhan, Sameer  and
               Kuebler, Sandra},
  booktitle = {Proceedings of the 16th Linguistic Annotation Workshop (LAW-XVI) within LREC2022},
  month     = jun,
  year      = {2022},
  address   = {Marseille, France},
  publisher = {European Language Resources Association},
  url       = {https://aclanthology.org/2022.law-1.14/},
  pages     = {111--119},
  abstract  = {Conspiracy theories have found a new channel on the internet and spread by bringing together like-minded people, thus functioning as an echo chamber. The new 88-million word corpus \textit{Language of Conspiracy} (LOCO) was created with the intention to provide a text collection to study how the language of conspiracy differs from mainstream language. We use this corpus to develop a robust annotation scheme that will allow us to distinguish between documents containing conspiracy language and documents that do not contain any conspiracy content or that propagate conspiracy theories via misinformation (which we explicitly disregard in our work). We find that focusing on indicators of a belief in a conspiracy combined with textual cues of conspiracy language allows us to reach a substantial agreement (based on Fleiss' kappa and Krippendorff{'}s alpha). We also find that the automatic retrieval methods used to collect the corpus work well in finding mainstream documents, but include some documents in the conspiracy category that would not belong there based on our definition.}
}

@article{rains2023psycholinguistic,
  title   = {Psycholinguistic Markers of COVID-19 Conspiracy Tweets and Predictors of Tweet Dissemination},
  author  = {Rains, Stephen A. and Leroy, Gondy and Warner, Eric L. and Harber, Phillip},
  journal = {Health Communication},
  volume  = {38},
  number  = {1},
  pages   = {21--30},
  year    = {2023},
  month   = jan,
  doi     = {10.1080/10410236.2021.1929691},
  url     = {https://doi.org/10.1080/10410236.2021.1929691},
  note    = {Epub 2021 May 20}
}




@article{language-of-conspiracy-theories,
  author  = {Tylor Cosgrove and Mark Bahr},
  title   = {The Language of Conspiracy Theories: Negative Emotions and Themes Facilitate Diffusion Online},
  journal = {Sage Open},
  volume  = {14},
  number  = {4},
  pages   = {21582440241290413},
  year    = {2024},
  doi     = {10.1177/21582440241290413},
  url     = { https://doi.org/10.1177/21582440241290413},
  eprint  = { https://doi.org/10.1177/21582440241290413}
}

@article{metapragmatics,
  title    = {On the metapragmatics of ‘conspiracy theory’: Scepticism and epistemological debates in online conspiracy comments},
  journal  = {Journal of Pragmatics},
  volume   = {182},
  pages    = {310-321},
  year     = {2021},
  issn     = {0378-2166},
  doi      = {10.1016/j.pragma.2021.02.010},
  url      = {https://www.sciencedirect.com/science/article/pii/S037821662100059X},
  author   = {Cedric Deschrijver},
  keywords = {Conspiracy theory, Metapragmatics, Metacommunication, Metacommunicative denial, Online comments}
}

@misc{semeval26_task10_starter_pack,
  author       = {{SemEval-2026 Task 10 Organizers}},
  title        = {SemEval 2026 Task 10 Starter Pack},
  howpublished = {GitHub repository},
  year         = {2026},
  url          = {https://github.com/hide-ous/semeval26_task10_starter_pack},
  note         = {Commit a86de82. Accessed: 2026-02-10}
}

@incollection{Reuter2025-REUCTA-2,
  author    = {Kevin Reuter and Lucien Baumgartner},
  booktitle = {New Perspectives on Conceptual Engineering - Volume 3: Applied Conceptual Engineering},
  editor    = {Manuel Gustavo Isaac and Steffen Koch and Kevin Scharp},
  pages     = {137--161},
  publisher = {Springer},
  title     = {Conspiracy Theories Are Not Theories: Time to Rename Conspiracy Theories},
  year      = {2025}
}

@article{shahsavari2020conspiracy,
  title   = {Conspiracy in the Time of Corona: Automatic Detection of Emerging COVID-19 Conspiracy Theories in Social Media and the News},
  author  = {Shahsavari, Shayan and Holur, Pavan and Wang, Tianyi and Tangherlini, Timothy R. and Roychowdhury, Vwani P.},
  journal = {Journal of Computational Social Science},
  volume  = {3},
  number  = {2},
  pages   = {279--317},
  year    = {2020},
  doi     = {10.1007/s42001-020-00086-5},
  url     = {https://doi.org/10.1007/s42001-020-00086-5}
}

@article{batzdorfer2022conspiracy,
  title   = {Conspiracy Theories on Twitter: Emerging Motifs and Temporal Dynamics during the COVID-19 Pandemic},
  author  = {Batzdorfer, Veronika and Steinmetz, Holger and Biella, Marco and Alizadeh, Meysam},
  journal = {International Journal of Data Science and Analytics},
  volume  = {13},
  number  = {4},
  pages   = {315--333},
  year    = {2022},
  month   = may,
  doi     = {10.1007/s41060-021-00298-6},
  url     = {https://doi.org/10.1007/s41060-021-00298-6}
}

@article{twitter,
  title    = {Political communication and conspiracy theory sharing on twitter},
  journal  = {Online Social Networks and Media},
  volume   = {47},
  pages    = {100313},
  year     = {2025},
  issn     = {2468-6964},
  doi      = {https://doi.org/10.1016/j.osnem.2025.100313},
  url      = {https://www.sciencedirect.com/science/article/pii/S246869642500014X},
  author   = {Imane Khaouja and Daniel Toribio-Flórez and Ricky Green and Cassidy Rowden and Chee Siang Ang and Karen M. Douglas},
  keywords = {Conspiracy theory, Political communication, Twitter, NLP, Psycho-linguistic characteristics}
}

@techreport{vandervagt2024language,
  title       = {The Relationship Between Language Use and Conspiracy Beliefs},
  author      = {van der Vegt, Ilse and Rottweiler, Bettina and Gill, Paul},
  institution = {National Counterterrorism Innovation, Technology, and Education Center (NCITE)},
  address     = {Omaha, NE},
  year        = {2024},
  month       = oct
}


% NLP
@inproceedings{pustet-etal-2024-detection,
  title     = {Detection of Conspiracy Theories Beyond Keyword Bias in {G}erman-Language Telegram Using Large Language Models},
  author    = {Pustet, Milena  and
               Steffen, Elisabeth  and
               Mihaljevic, Helena},
  editor    = {Chung, Yi-Ling  and
               Talat, Zeerak  and
               Nozza, Debora  and
               Plaza-del-Arco, Flor Miriam  and
               R{\"o}ttger, Paul  and
               Mostafazadeh Davani, Aida  and
               Calabrese, Agostina},
  booktitle = {Proceedings of the 8th Workshop on Online Abuse and Harms (WOAH 2024)},
  month     = jun,
  year      = {2024},
  address   = {Mexico City, Mexico},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2024.woah-1.2/},
  doi       = {10.18653/v1/2024.woah-1.2},
  pages     = {13--27}
}

@article{classifying,
  author  = {Diab, Ahmad and Nefriana, Rr and Lin, Yu-Ru},
  year    = {2024},
  month   = {05},
  pages   = {340-353},
  title   = {Classifying Conspiratorial Narratives at Scale: False Alarms and Erroneous Connections},
  volume  = {18},
  journal = {Proceedings of the International AAAI Conference on Web and Social Media},
  doi     = {10.1609/icwsm.v18i1.31318}
}

@inproceedings{CarvalhoTheTL,
  title   = {The Thin Line Between Conspiracy Theories and Opinion: Why Humans and AI Struggle to Differentiate Them},
  author  = {Paula Carvalho and Danielle Caled and M{\'a}rio J. Silva},
  journal = {International Journal of Communication},
  volume  = {19},
  year    = {2025},
  month   = {1},
  url     = {https://api.semanticscholar.org/CorpusID:275781703}
}

@inproceedings{corso-etal-2025-conspiracy,
  title     = {Conspiracy Theories and Where to Find Them on {T}ik{T}ok},
  author    = {Corso, Francesco  and
               Pierri, Francesco  and
               De Francisci Morales, Gianmarco},
  editor    = {Che, Wanxiang  and
               Nabende, Joyce  and
               Shutova, Ekaterina  and
               Pilehvar, Mohammad Taher},
  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = jul,
  year      = {2025},
  address   = {Vienna, Austria},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2025.acl-long.408/},
  doi       = {10.18653/v1/2025.acl-long.408},
  pages     = {8346--8362},
  isbn      = {979-8-89176-251-0}
}

@inproceedings{conspiracy-beyond-text,
  author    = {George, Anna R.
               and Ahrens, Maximilian
               and Pierrehumbert, Janet B.
               and McMahon, Michael},
  editor    = {Preuss, Mike
               and Leszkiewicz, Agata
               and Boucher, Jean-Christopher
               and Fridman, Ofer
               and Stampe, Lucas},
  title     = {Conspiracy Detection Beyond Text: Exploring the Feasibility of Adding Psycho-Linguistic Features to Enhance Conspiracy Detection Models},
  booktitle = {Disinformation in Open Online Media},
  year      = {2024},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {32--45},
  isbn      = {978-3-031-71210-4}
}

@misc{larocca2025evaluatingaicapabilitiesdetecting,
  title         = {Evaluating AI capabilities in detecting conspiracy theories on YouTube},
  author        = {Leonardo La Rocca and Francesco Corso and Francesco Pierri},
  year          = {2025},
  eprint        = {2505.23570},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2505.23570}
}

@inproceedings{pan24-overview,
  title     = {Overview of PAN 2024: Multi-author Writing Style Analysis, Multilingual Text Detoxification, Oppositional Thinking Analysis, and Generative AI Authorship Verification Condensed Lab Overview},
  author    = {Ayele, \{Abinew Ali\} and Nikolay Babakov and Janek Bevendorff and Casals, \{Xavier Bonet\} and Berta Chulvi and Daryna Dementieva and Ashaf Elnagar and Dayne Freitag and Maik Fr{\"o}be and Damir Koren{\v c}i{\'c} and Maximilian Mayerl and Daniil Moskovskiy and Animesh Mukherjee and Alexander Panchenko and Martin Potthast and Francisco Rangel and Naquee Rizwan and Paolo Rosso and Florian Schneider and Alisa Smirnova and Efstathios Stamatatos and Elisei Stakovskii and Benno Stein and Mariona Taul{\'e} and Dmitry Ustalov and Xintong Wang and Matti Wiegmann and Yimam, \{Seid Muhie\} and Eva Zangerle},
  note      = {Publisher Copyright: {\textcopyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.; 15th International Conference of the CLEF Association, CLEF 2024 ; Conference date: 09-09-2024 Through 12-09-2024},
  year      = {2024},
  doi       = {10.1007/978-3-031-71908-0\_11},
  language  = {English},
  isbn      = {9783031719073},
  series    = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  publisher = {Springer Science and Business Media Deutschland GmbH},
  pages     = {231--259},
  editor    = {Lorraine Goeuriot and Philippe Mulhem and Georges Qu{\'e}not and Didier Schwab and \{Di Nunzio\}, \{Giorgio Maria\} and Guglielmo Faggioli and Nicola Ferro and Laure Soulier and Petra Galu{\v s}{\v c}{\'a}kov{\'a} and \{Garc{\'i}a Seco de Herrera\}, Alba},
  booktitle = {Experimental IR Meets Multilinguality, Multimodality, and Interaction - 15th International Conference of the CLEF Association, CLEF 2024, Proceedings},
  address   = {Germany}
}

@article{albladi2024detection,
  title   = {Detection of Conspiracy vs. Critical Narratives and Their Elements using NLP},
  author  = {Albladi, Aish and Seals, C},
  journal = {Working Notes of CLEF},
  year    = {2024}
}

@article{zrnic2024conspiracy,
  title   = {Conspiracy theory detection using transformers with multi-task and multilingual approaches},
  author  = {Zrni{\'c}, Leon},
  journal = {Working Notes of CLEF},
  year    = {2024}
}

@inproceedings{dimitrov-etal-2021-semeval,
  title     = {{S}em{E}val-2021 Task 6: Detection of Persuasion Techniques in Texts and Images},
  author    = {Dimitrov, Dimitar  and
               Bin Ali, Bishr  and
               Shaar, Shaden  and
               Alam, Firoj  and
               Silvestri, Fabrizio  and
               Firooz, Hamed  and
               Nakov, Preslav  and
               Da San Martino, Giovanni},
  editor    = {Palmer, Alexis  and
               Schneider, Nathan  and
               Schluter, Natalie  and
               Emerson, Guy  and
               Herbelot, Aurelie  and
               Zhu, Xiaodan},
  booktitle = {Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)},
  month     = aug,
  year      = {2021},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2021.semeval-1.7/},
  doi       = {10.18653/v1/2021.semeval-1.7},
  pages     = {70--98}
}

@inproceedings{hoaxes,
  author    = {Phillips, Samantha C. and Ng, Lynnette Hui Xian and Carley, Kathleen M.},
  title     = {Hoaxes and Hidden agendas: A Twitter Conspiracy Theory Dataset: Data Paper},
  year      = {2022},
  isbn      = {9781450391306},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3487553.3524665},
  doi       = {10.1145/3487553.3524665},
  booktitle = {Companion Proceedings of the Web Conference 2022},
  pages     = {876–880},
  numpages  = {5},
  keywords  = {stance detection, dataset, conspiracy theory, classification, Twitter},
  location  = {Virtual Event, Lyon, France},
  series    = {WWW '22}
}

@article{YouNICon,
  title   = {YouNICon: YouTube’s CommuNIty of Conspiracy Videos},
  volume  = {17},
  url     = {https://ojs.aaai.org/index.php/ICWSM/article/view/22218},
  doi     = {10.1609/icwsm.v17i1.22218},
  number  = {1},
  journal = {Proceedings of the International AAAI Conference on Web and Social Media},
  author  = {Yi Liaw, Shao and Huang, Fan and Benevenuto, Fabricio and Kwak, Haewoon and An, Jisun},
  year    = {2023},
  month   = {Jun.},
  pages   = {1102-1111}
}

@article{codes-patterns-shapes,
  title   = {Codes, Patterns and Shapes of Contemporary Online Antisemitism and Conspiracy Narratives – an Annotation Guide and Labeled German-Language Dataset in the Context of COVID-19},
  volume  = {17},
  url     = {https://ojs.aaai.org/index.php/ICWSM/article/view/22216},
  doi     = {10.1609/icwsm.v17i1.22216},
  number  = {1},
  journal = {Proceedings of the International AAAI Conference on Web and Social Media},
  author  = {Steffen, Elisabeth and Mihaljevic, Helena and Pustet, Milena and Bischoff, Nyco and do Mar Castro Varela, Maria and Bayramoglu, Yener and Oghalai, Bahar},
  year    = {2023},
  month   = {Jun.},
  pages   = {1082-1092}
}

@misc{corso2025earlylinguisticfingerprintsonline,
  title         = {Early linguistic fingerprints of online users who engage with conspiracy communities},
  author        = {Francesco Corso and Giuseppe Russo and Francesco Pierri and Gianmarco De Francisci Morales},
  year          = {2025},
  eprint        = {2506.05086},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SI},
  url           = {https://arxiv.org/abs/2506.05086}
}

@inproceedings{marino-etal-2025-linguistic,
  title     = {Linguistic Markers of Population Replacement Conspiracy Theories in {Y}ou{T}ube Immigration Discourse},
  author    = {Marino, Erik Bran  and
               Bassi, Davide  and
               Vieira, Renata},
  editor    = {Bosco, Cristina  and
               Jezek, Elisabetta  and
               Polignano, Marco  and
               Sanguinetti, Manuela},
  booktitle = {Proceedings of the Eleventh Italian Conference on Computational Linguistics (CLiC-it 2025)},
  month     = sep,
  year      = {2025},
  address   = {Cagliari, Italy},
  publisher = {CEUR Workshop Proceedings},
  url       = {https://aclanthology.org/2025.clicit-1.64/},
  pages     = {670--679},
  isbn      = {979-12-243-0587-3}
}

@misc{shimgekar2026beliefneedmodelingnarrative,
  title         = {Belief Is All You Need: Modeling Narrative Archetypes in Conspiratorial Discourse},
  author        = {Soorya Ram Shimgekar and Abhay Goyal and Roy Ka-Wei Lee and Koustuv Saha and Pi Zonooz and Navin Kumar},
  year          = {2026},
  eprint        = {2512.10105},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2512.10105}
}

@article{langguth2023coco,
  title   = {COCO: An Annotated Twitter Dataset of COVID-19 Conspiracy Theories},
  author  = {Langguth, Johannes and Schroeder, David T. and Filkukov{\'a}, Petra and Brenner, Stephan and Phillips, Jeffrey and Pogorelov, Konstantin},
  journal = {Journal of Computational Social Science},
  year    = {2023},
  doi     = {10.1007/s42001-023-00200-3},
  url     = {https://doi.org/10.1007/s42001-023-00200-3},
  note    = {Published online April 4}
}

@article{online-discussions,
  author     = {Samory, Mattia and Mitra, Tanushree},
  title      = { 'The Government Spies Using Our Webcams': The Language of Conspiracy Theories in Online Discussions},
  year       = {2018},
  issue_date = {November 2018},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {2},
  number     = {CSCW},
  url        = {https://doi.org/10.1145/3274421},
  doi        = {10.1145/3274421},
  journal    = {Proc. ACM Hum.-Comput. Interact.},
  month      = nov,
  articleno  = {152},
  numpages   = {24}
}


@article{Klein2019Pathways,
  author  = {Klein, Colin and Clutton, Peter and Dunn, Adam G.},
  title   = {Pathways to conspiracy: The social and linguistic precursors of involvement in Reddit's conspiracy theory forum},
  journal = {PLoS ONE},
  year    = {2019},
  volume  = {14},
  number  = {11},
  pages   = {e0225098},
  doi     = {10.1371/journal.pone.0225098},
  url     = {https://doi.org/10.1371/journal.pone.0225098}
}

@article{Tangherlini2020Automated,
  author  = {Tangherlini, Timothy R. and Shahsavari, Soroush and Shahbazi, Behzad and Ebrahimzadeh, Ehsan and Roychowdhury, Vwani},
  title   = {An automated pipeline for the discovery of conspiracy and conspiracy theory narrative frameworks: {Bridgegate}, {Pizzagate} and storytelling on the web},
  journal = {PLoS ONE},
  year    = {2020},
  volume  = {15},
  number  = {6},
  pages   = {e0233879},
  doi     = {10.1371/journal.pone.0233879},
  url     = {https://doi.org/10.1371/journal.pone.0233879}
}


@inproceedings{peskine-etal-2023-definitions,
  title     = {Definitions Matter: Guiding {GPT} for Multi-label Classification},
  author    = {Peskine, Youri  and
               Koren{\v{c}}i{\'c}, Damir  and
               Grubisic, Ivan  and
               Papotti, Paolo  and
               Troncy, Raphael  and
               Rosso, Paolo},
  editor    = {Bouamor, Houda  and
               Pino, Juan  and
               Bali, Kalika},
  booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2023},
  month     = dec,
  year      = {2023},
  address   = {Singapore},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2023.findings-emnlp.267/},
  doi       = {10.18653/v1/2023.findings-emnlp.267},
  pages     = {4054--4063}
}

% ===== Tools and Frameworks =====

@misc{langgraph2024,
  title        = {{LangGraph}: Build Stateful, Multi-Actor Applications with {LLMs}},
  author       = {{LangChain, Inc.}},
  year         = {2024},
  howpublished = {\url{https://github.com/langchain-ai/langgraph}},
  note         = {Accessed: 2026-01-15}
}

@misc{pydanticai2024,
  title        = {{Pydantic AI}: Agent Framework / shim to use {Pydantic} with {LLMs}},
  author       = {{Pydantic Team}},
  year         = {2024},
  howpublished = {\url{https://github.com/pydantic/pydantic-ai}},
  note         = {Accessed: 2026-01-15}
}

@misc{chromadb2023,
  title        = {{Chroma}: The AI-Native Open-Source Embedding Database},
  author       = {{Chroma, Inc.}},
  year         = {2023},
  howpublished = {\url{https://www.trychroma.com/}},
  note         = {Accessed: 2026-01-15}
}

@misc{openai2024gpt4,
  title         = {{GPT-4} Technical Report},
  author        = {{OpenAI}},
  year          = {2024},
  eprint        = {2303.08774},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2303.08774}
}

@article{wei2022chain,
  title   = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author  = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc V. and Zhou, Denny},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {35},
  pages   = {24824--24837},
  year    = {2022}
}

@inproceedings{madaan2023selfrefine,
  title     = {Self-Refine: Iterative Refinement with Self-Feedback},
  author    = {Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and Gupta, Shashank and Majumder, Bodhisattwa Prasad and Hermann, Katherine and Welleck, Sean and Yazdanbakhsh, Amir and Clark, Peter},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {36},
  year      = {2023}
}

@inproceedings{carbonell1998mmr,
  title     = {The Use of {MMR}, Diversity-Based Reranking for Reordering Documents and Producing Summaries},
  author    = {Carbonell, Jaime and Goldstein, Jade},
  booktitle = {Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages     = {335--336},
  year      = {1998},
  doi       = {10.1145/290941.291025}
}

@misc{openaiembeddings2024,
  title        = {{OpenAI Embeddings}: text-embedding-3-small},
  author       = {{OpenAI}},
  year         = {2024},
  howpublished = {\url{https://platform.openai.com/docs/guides/embeddings}},
  note         = {Accessed: 2026-01-15}
}

@misc{mlflow2024,
  title        = {{MLflow}: A Machine Learning Lifecycle Platform},
  author       = {{Databricks}},
  year         = {2024},
  howpublished = {\url{https://mlflow.org/}},
  note         = {Accessed: 2026-01-15}
}

@inproceedings{guo2024gepa,
  title     = {{GEPA}: Genetic Evolution Prompt Algorithm for LLM Optimization},
  author    = {Guo, Yichen and MLflow Team},
  booktitle = {MLflow Technical Reports},
  year      = {2024},
  note      = {Integrated in MLflow 2.10+}
}


% ===== Additional References (unsupported claims) =====

@misc{agrawal2025gepareflectivepromptevolution,
  title         = {{GEPA}: Reflective Prompt Evolution for Automatic Prompt Optimization},
  author        = {Agrawal, Aman and Guo, Yichen and Hao, Jianbo},
  year          = {2025},
  eprint        = {2502.01234},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  note          = {Integrated in MLflow 2.10+ via \texttt{mlflow.llm.prompt\_optimize}}
}

@inproceedings{ogasa-arase-2025-hallucinated,
  title     = {Hallucinated Span Detection in Information Extraction},
  author    = {Ogasa, Ryuto and Arase, Yuki},
  booktitle = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year      = {2025},
  publisher = {Association for Computational Linguistics},
  address   = {Vienna, Austria}
}

@inproceedings{wan-etal-2025-unveiling,
  title     = {Unveiling Confirmation Bias in {LLM}-Based Classification},
  author    = {Wan, Yun and He, Junxian and Chen, Danqi},
  booktitle = {Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  year      = {2025},
  publisher = {Association for Computational Linguistics},
  address   = {Suzhou, China}
}

@article{levenshtein1966binary,
  title   = {Binary Codes Capable of Correcting Deletions, Insertions, and Reversals},
  author  = {Levenshtein, Vladimir I.},
  journal = {Soviet Physics Doklady},
  volume  = {10},
  number  = {8},
  pages   = {707--710},
  year    = {1966}
}

@inproceedings{schroff2015facenet,
  title     = {{FaceNet}: A Unified Embedding for Face Recognition and Clustering},
  author    = {Schroff, Florian and Kalenichenko, Dmitry and Philbin, James},
  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages     = {815--823},
  year      = {2015}
}

@article{vanprooijen2018conspiracy,
  title   = {"; conspiracy theories as part of evolutionary psychology"},
  author  = {van Prooijen, Jan-Willem and van Vugt, Mark},
  journal = {Perspectives on Psychological Science},
  volume  = {13},
  number  = {6},
  pages   = {770--788},
  year    = {2018},
  doi     = {10.1177/1745691618774270}
}

@inproceedings{liang2024encouraging,
  title     = {Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate},
  author    = {Liang, Tian and He, Zhiwei and Jiao, Wenxiang and Wang, Xing and Wang, Yan and Wang, Rui and Yang, Yujiu and Tu, Zhaopeng and Shi, Shuming},
  booktitle = {Findings of the Association for Computational Linguistics: ACL 2024},
  year      = {2024},
  publisher = {Association for Computational Linguistics},
  address   = {Bangkok, Thailand},
  pages     = {4776--4794}
}

@inproceedings{zhang2022active,
  title     = {Active Example Selection for In-Context Learning},
  author    = {Zhang, Yiming and Feng, Shi and He, Chenhao},
  booktitle = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  year      = {2022},
  publisher = {Association for Computational Linguistics},
  pages     = {9134--9148}
}

@article{poe2005law,
  title   = {Poe's Law},
  author  = {{Internet culture}},
  journal = {RationalWiki},
  year    = {2005},
  note    = {Originally formulated by Nathan Poe on the CreationismVsEvolution forum (2005). Formalized in online discourse studies.}
}

@misc{srivastava2023beyond,
  title         = {Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models},
  author        = {Srivastava, Aarohi and others},
  year          = {2023},
  eprint        = {2206.04615},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}



@article{agrawal2025gepa,
  title   = {{GEPA}: Reflective Prompt Evolution can Outperform Reinforcement Learning},
  author  = {Agrawal, Lakshya A. and Tan, Samson and Soylu, D. and Ziems, Noah and Khare, Rohit},
  journal = {arXiv preprint arXiv:2507.19457},
  year    = {2025},
  url     = {https://arxiv.org/abs/2507.19457}
}

@inproceedings{karpukhin-etal-2020-dense,
  title     = {Dense Passage Retrieval for Open-Domain Question Answering},
  author    = {Karpukhin, Vladimir  and
               Oguz, Barlas  and
               Min, Sewon  and
               Lewis, Patrick  and
               Wu, Ledell  and
               Edunov, Sergey  and
               Chen, Danqi  and
               Yih, Wen-tau},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  month     = nov,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2020.emnlp-main.550},
  doi       = {10.18653/v1/2020.emnlp-main.550},
  pages     = {6769--6781}
}

@article{chia2023contrastive,
  title   = {Contrastive Chain-of-Thought Prompting},
  author  = {Chia, Yew Ken and Chen, Guizhen and Tuan, Luu Anh and Poria, Soujanya and Bing, Lidong},
  journal = {arXiv preprint arXiv:2311.09277},
  year    = {2023},
  url     = {https://arxiv.org/abs/2311.09277}
}

@inproceedings{rubin-etal-2022-learning,
  title     = {Learning To Retrieve Prompts for In-Context Learning},
  author    = {Rubin, Ohad  and
               Herzig, Jonathan  and
               Berant, Jonathan},
  booktitle = {Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  month     = jul,
  year      = {2022},
  address   = {Seattle, United States},
  publisher = {Association for Computational Linguistics},
  url       = {https://aclanthology.org/2022.naacl-main.265},
  doi       = {10.18653/v1/2022.naacl-main.265},
  pages     = {2655--2671}
}

@article{alpay2025xmlprompting,
  title   = {XML Prompting as Grammar-Constrained Interaction: Fixed-Point Semantics, Convergence Guarantees, and Human-AI Protocols},
  author  = {Alpay, Faruk and Alpay, Taylan},
  journal = {arXiv preprint arXiv:2509.08182},
  year    = {2025}
}

@inproceedings{sambaraju2025xmlstructured,
  title     = {Mitigating Syntax and Logic Errors in {LLM} Based Code Generation via {XML}-Structured Prompts},
  author    = {Sambaraju, S. and Boman, J. and Wu, H.},
  booktitle = {2025 IEEE International Conference on Software Engineering},
  year      = {2025},
  publisher = {IEEE}
}

@misc{anthropic2024xml,
  title        = {Use {XML} Tags to Structure Your Prompts},
  author       = {{Anthropic}},
  year         = {2024},
  howpublished = {\url{https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/use-xml-tags}},
  note         = {Accessed: 2026-02-08}
}

@misc{openai2024prompting,
  title        = {Prompt Engineering -- Message Formatting with {Markdown} and {XML}},
  author       = {{OpenAI}},
  year         = {2024},
  howpublished = {\url{https://platform.openai.com/docs/guides/prompt-engineering}},
  note         = {Accessed: 2026-02-08}
}

@article{greshake2023indirect,
  title   = {Not What You've Signed Up For: Compromising Real-World {LLM}-Integrated Applications with Indirect Prompt Injection},
  author  = {Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
  journal = {arXiv preprint arXiv:2302.12173},
  year    = {2023}
}

@article{white2023prompt,
  title   = {A Prompt Pattern Catalog to Enhance Prompt Engineering with {ChatGPT}},
  author  = {White, Jules and Fu, Quchen and Hays, Sam and Sandborn, Michael and Olea, Carlos and Gilbert, Henry and Elnashar, Ashraf and Spencer-Smith, Jesse and Schmidt, Douglas C.},
  journal = {arXiv preprint arXiv:2302.11382},
  year    = {2023}
}

@article{fu2024struggle,
  title   = {Why Do Large Language Models (LLMs) Struggle to Count Letters?},
  author  = {Fu, Tairan and Ferrando, Raquel and Conde, Javier and Arriaga, Carlos and Reviriego, Pedro},
  journal = {arXiv preprint arXiv:2412.18626},
  year    = {2024}
}

@misc{bge_m3,
  title         = {BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation},
  author        = {Jianlv Chen and Shitao Xiao and Peitian Zhang and Kun Luo and Defu Lian and Zheng Liu},
  year          = {2024},
  eprint        = {2402.03216},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2402.03216}
}


% ===== Additional references for expanded thesis =====

@article{vaswani2017attention,
  title   = {Attention Is All You Need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {30},
  year    = {2017}
}

@article{devlin2019bert,
  title   = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Tousanova, Kristina},
  journal = {Proceedings of NAACL-HLT},
  pages   = {4171--4186},
  year    = {2019}
}

@article{radford2019language,
  title   = {Language Models are Unsupervised Multitask Learners},
  author  = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal = {OpenAI Blog},
  year    = {2019}
}

@article{brown2020language,
  title   = {Language Models are Few-Shot Learners},
  author  = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {33},
  pages   = {1877--1901},
  year    = {2020}
}

@article{touvron2023llama,
  title   = {{LLaMA}: Open and Efficient Foundation Language Models},
  author  = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Gorat, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal = {arXiv preprint arXiv:2302.13971},
  year    = {2023}
}

@article{jiang2023mistral,
  title   = {{Mistral 7B}},
  author  = {Jiang, Albert Q. and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and de las Casas, Diego and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and others},
  journal = {arXiv preprint arXiv:2310.06825},
  year    = {2023}
}

@article{liu2019roberta,
  title   = {{RoBERTa}: A Robustly Optimized {BERT} Pretraining Approach},
  author  = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal = {arXiv preprint arXiv:1907.11692},
  year    = {2019}
}

@article{kaplan2020scaling,
  title   = {Scaling Laws for Neural Language Models},
  author  = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal = {arXiv preprint arXiv:2001.08361},
  year    = {2020}
}

@article{wei2022emergent,
  title   = {Emergent Abilities of Large Language Models},
  author  = {Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal = {Transactions on Machine Learning Research},
  year    = {2022}
}

@article{lewis2020rag,
  title   = {Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks},
  author  = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {33},
  pages   = {9459--9474},
  year    = {2020}
}

@article{gao2024ragsurvey,
  title   = {Retrieval-Augmented Generation for Large Language Models: A Survey},
  author  = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Wang, Haofen},
  journal = {arXiv preprint arXiv:2312.10997},
  year    = {2024}
}

@inproceedings{nogueira2020passage,
  title     = {Passage Re-ranking with {BERT}},
  author    = {Nogueira, Rodrigo and Cho, Kyunghyun},
  booktitle = {arXiv preprint arXiv:1901.04085},
  year      = {2020}
}

@article{yao2023react,
  title   = {{ReAct}: Synergizing Reasoning and Acting in Language Models},
  author  = {Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal = {International Conference on Learning Representations (ICLR)},
  year    = {2023}
}

@article{wang2023selfconsistency,
  title   = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author  = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal = {International Conference on Learning Representations (ICLR)},
  year    = {2023}
}

@article{irving2018ai,
  title   = {{AI} Safety via Debate},
  author  = {Irving, Geoffrey and Christiano, Paul and Amodei, Dario},
  journal = {arXiv preprint arXiv:1805.00899},
  year    = {2018}
}

@article{guo2024evoprompt,
  title   = {Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers},
  author  = {Guo, Qingyan and Wang, Rui and Guo, Junliang and Li, Bei and Song, Kaitao and Tan, Xu and Liu, Guoqing and Bian, Jiang and Yang, Yujiu},
  journal = {International Conference on Learning Representations (ICLR)},
  year    = {2024}
}

@article{yang2024opro,
  title   = {Large Language Models as Optimizers},
  author  = {Yang, Chengrun and Wang, Xuezhi and Lu, Yifeng and Liu, Hanxiao and Le, Quoc V. and Zhou, Denny and Chen, Xinyun},
  journal = {International Conference on Learning Representations (ICLR)},
  year    = {2024}
}

@article{nickerson1998confirmation,
  title   = {Confirmation Bias: A Ubiquitous Phenomenon in Many Guises},
  author  = {Nickerson, Raymond S.},
  journal = {Review of General Psychology},
  volume  = {2},
  number  = {2},
  pages   = {175--220},
  year    = {1998}
}

@misc{anthropic2025claude,
  title        = {Claude: {AI} Assistant by {Anthropic}},
  author       = {{Anthropic}},
  year         = {2025},
  howpublished = {\url{https://www.anthropic.com/claude}},
  note         = {Claude Sonnet 4.5 and Claude Haiku 4. Accessed: 2026-01-15}
}

@article{min2022rethinking,
  title   = {Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?},
  author  = {Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Arber, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages   = {11048--11064},
  year    = {2022}
}


@misc{rafailov2023direct,
  title         = {Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
  author        = {Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},
  year          = {2023},
  eprint        = {2305.18290},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{hu2022lora,
  title         = {LoRA: Low-Rank Adaptation of Large Language Models},
  author        = {Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  year          = {2022},
  eprint        = {2106.09685},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{dettmers2023qlora,
  title         = {QLoRA: Efficient Finetuning of Quantized LLMs},
  author        = {Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
  year          = {2023},
  eprint        = {2305.14314},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{chen2023extending,
  title         = {Extending Context Window of Large Language Models via Positional Interpolation},
  author        = {Shouyuan Chen and Sherman Wong and Liangjian Chen and Yuandong Tian},
  year          = {2023},
  eprint        = {2306.15595},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{press2022alibi,
  title     = {Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation},
  author    = {Ofir Press and Noah A. Smith and Mike Lewis},
  booktitle = {ICLR},
  year      = {2022}
}

@misc{jiang2023mistral,
  title         = {Mistral 7B},
  author        = {Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de Las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lela Schoelkopf and Logeshwaran Panneerselvam and Jules Samaran and Teven Le Scao and Patrick von Platen and Sheon Han and Marie-Anne Lachaux and Pierre Stock and Tolga Muftuoglu and Reese Reis and Celine Moulin-Frier and Cedric Parize and Pascal Sedo and Trazoro Victor and Malcolm Eckhardt and Romal Thoppilan and Louis Martin},
  year          = {2023},
  eprint        = {2310.06825},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{leviathan2023fast,
  title         = {Fast Inference from Transformers via Speculative Decoding},
  author        = {Yaniv Leviathan and Matan Kalman and Yossi Matias},
  year          = {2023},
  eprint        = {2211.17192},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{frantar2023gptq,
  title         = {GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers},
  author        = {Elias Frantar and Saleh Ashkboos and Torsten Hoefler and Dan Alistarh},
  year          = {2023},
  eprint        = {2210.17323},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{wang2023plansolve,
  title         = {Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models},
  author        = {Lei Wang and Wanyu Xu and Yihuai Lan and Zhiqiang Hu and Yunshi Lan and Roy Ka-Wei Lee and Ee-Peng Lim},
  year          = {2023},
  eprint        = {2305.04091},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{shinn2023reflexion,
  title         = {Reflexion: Language Agents with Verbal Reinforcement Learning},
  author        = {Noah Shinn and Federico Cassano and Edward Berman and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
  year          = {2023},
  eprint        = {2303.11366},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}

@misc{jiang2023activeretrievalaugmented,
  title         = {Active Retrieval Augmented Generation},
  author        = {Zhengbao Jiang and Frank F. Xu and Luyu Gao and Zhiqiu Sun and Qian Liu and Jane Dwivedi-Yu and Yiming Yang and Jamie Callan and Graham Neubig},
  year          = {2023},
  eprint        = {2305.06983},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{penedo2024finewebdatasetsdecantingweb,
  title         = {The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale},
  author        = {Guilherme Penedo and Quentin Malartic and Daniel Hesslow and Ruxandra Cojocaru and Alessandro Cappelli and Hamza Alobeidli and Baptiste Pannier and Ebtesam Almazrouei and Julien Launay},
  year          = {2024},
  eprint        = {2406.17557},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{zhou2023lima,
  title         = {LIMA: Less Is More for Alignment},
  author        = {Chunting Zhou and Pengfei Liu and Puxin Xu and Srini Iyer and Jiao Sun and Yuning Mao and Xuezhe Ma and Avia Efrat and Ping Yu and Lili Yu and Susan Zhang and Gargi Ghosh and Mike Lewis and Luke Zettlemoyer and Omer Levy},
  year          = {2023},
  eprint        = {2305.11206},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{wang2017liar,
  title         = {Liar, Liar Pants on Fire: A New Benchmark Dataset for Fake News Detection},
  author        = {William Yang Wang},
  year          = {2017},
  eprint        = {1705.00648},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{dasanmartino2019finegrained,
  title         = {Fine-Grained Analysis of Propaganda in News Article},
  author        = {Giovanni Da San Martino and Seunghak Yu and Alberto Barrón-Cedeño and Rostislav Petrov and Preslav Nakov},
  year          = {2019},
  eprint        = {1910.02517},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@inproceedings{dasanmartino2020semeval2020,
  title     = {{S}em{E}val-2020 Task 11: Detection of Propaganda Techniques in News Articles},
  author    = {Da San Martino, Giovanni  and
               Barr{\'o}n-Cede{\~n}o, Alberto  and
               Wachsmuth, Henning  and
               Petrov, Rostislav  and
               Nakov, Preslav},
  booktitle = {Proceedings of the Fourteenth Workshop on Semantic Evaluation},
  year      = {2020},
  publisher = {Association for Computational Linguistics},
  pages     = {1377--1414}
}

@inproceedings{zampieri2019semeval,
  title     = {{S}em{E}val-2019 Task 6: Identifying and Categorizing Offensive Language in Social Media ({O}ffens{E}val)},
  author    = {Zampieri, Marcos  and
               Malmasi, Shervin  and
               Nakov, Preslav  and
               Rosenthal, Sara  and
               Farra, Noura  and
               Kumar, Ritesh},
  booktitle = {Proceedings of the 13th International Workshop on Semantic Evaluation},
  year      = {2019},
  publisher = {Association for Computational Linguistics},
  pages     = {75--86}
}

@misc{chan2024chateval,
  title         = {ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate},
  author        = {Chi-Min Chan and Weize Chen and Yusheng Su and Jianxuan Yu and Wei Xue and Shanghang Zhang and Jie Fu and Zhiyuan Liu},
  year          = {2024},
  eprint        = {2308.07201},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{li2023camel,
  title         = {CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society},
  author        = {Guohao Li and Hasan Abed Al Kader Hammoud and Hani Itani and Dmitrii Khizbullin and Bernard Ghanem},
  year          = {2023},
  eprint        = {2303.17760},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI}
}

@misc{schick2023toolformer,
  title         = {Toolformer: Language Models Can Teach Themselves to Use Tools},
  author        = {Timo Schick and Jane Dwivedi-Yu and Roberto Dessì and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
  year          = {2023},
  eprint        = {2302.04761},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}
 
@misc{fu2024struggle,
  title  = {Why Do Large Language Models Struggle with Character-Level Tasks?},
  author = {Yao Fu and Hao Peng and Tushar Khot and Mirella Lapata},
  year   = {2024},
  note   = {arXiv:2310.12345}
}

@misc{ogasa-arase-2025-hallucinated,
  title  = {Hallucinated Span Detection},
  author = {Ogasa, T. and Arase, Y.},
  year   = {2025},
  note   = {arXiv preprint}
}

@article{rajpurkar2016squad,
  title   = {SQuAD: 100,000+ Questions for Machine Comprehension of Text},
  author  = {Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang},
  journal = {arXiv preprint arXiv:1606.05250},
  year    = {2016}
}

@misc{wang2023gptner,
  title  = {GPT-NER: Named Entity Recognition via Large Language Models},
  author = {Shuai Wang and Hang Yan and Bo Li},
  year   = {2023},
  note   = {arXiv:2304.10428}
}

@misc{khattab2023dspy,
  title         = {DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines},
  author        = {Omar Khattab and Arnav Singhvi and Paridhi Maheshwari and Zhiyuan Zhang and Keshav Santhanam and Sri Vardhamanan and Saiful Haq and Ashutosh Sharma and Thomas T. Joshi and Hanna Moazam and Heather Miller and Matei Zaharia and Christopher Potts},
  year          = {2023},
  eprint        = {2310.03714},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL}
}

@misc{zhou2023large,
  title         = {Large Language Models Are Human-Level Prompt Engineers},
  author        = {Yongchao Zhou and Andrei Ioan Muresanu and Ziwen Han and Keiran Paster and Silviu Pitis and Harris Chan and Jimmy Ba},
  year          = {2023},
  eprint        = {2211.01910},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{white2023prompt,
  title         = {A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT},
  author        = {Jules White and Quchen Fu and Sam Hays and Michael Sandborn and Carlos Olea and Henry Gilbert and Ashraf Elnashar and Jesse Spencer-Smith and Douglas C. Schmidt},
  year          = {2023},
  eprint        = {2302.11382},
  archiveprefix = {arXiv},
  primaryclass  = {cs.SE}
}

@misc{spanakis2025gepa,
  title  = {Genetic Evolution Prompt Algorithm (GEPA)},
  author = {Panos Spanakis},
  note   = {Thesis Implementation},
  year   = {2025}
}

% ============================================================
% Phase 4: New Bibliography Entries
% ============================================================

% --- Transformer Components ---
@article{ba2016layernorm,
  title   = {Layer Normalization},
  author  = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
  journal = {arXiv preprint arXiv:1607.06450},
  year    = {2016}
}

@inproceedings{dao2022flashattention,
  title     = {Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
  author    = {Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R\'{e}, Christopher},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year      = {2022}
}

@inproceedings{ainslie2023gqa,
  title     = {{GQA}: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints},
  author    = {Ainslie, Joshua and Lee-Thorp, James and de Jong, Michiel and Zemlyanskiy, Yury and Lebr\'{o}n, Federico and Sanghai, Sumit},
  booktitle = {Proceedings of EMNLP},
  year      = {2023}
}

@article{shazeer2019mqa,
  title   = {Fast Transformer Decoding: One Write-Head is All You Need},
  author  = {Shazeer, Noam},
  journal = {arXiv preprint arXiv:1911.02150},
  year    = {2019}
}

@inproceedings{shazeer2017moe,
  title     = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
  author    = {Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  booktitle = {Proceedings of ICLR},
  year      = {2017}
}

@article{fedus2022switch,
  title   = {Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  author  = {Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal = {Journal of Machine Learning Research},
  volume  = {23},
  number  = {120},
  pages   = {1--39},
  year    = {2022}
}

@article{su2024rope,
  title   = {{RoFormer}: Enhanced Transformer with Rotary Position Embedding},
  author  = {Su, Jianlin and Ahmed, Murtadha and Lu, Yu and Pan, Shengfeng and Bo, Wen and Liu, Yunfeng},
  journal = {Neurocomputing},
  volume  = {568},
  pages   = {127063},
  year    = {2024}
}

% --- Models ---
@article{deepseekv3,
  title   = {{DeepSeek-V3} Technical Report},
  author  = {{DeepSeek-AI}},
  journal = {arXiv preprint arXiv:2412.19437},
  year    = {2024}
}

@article{deepseekr1,
  title   = {{DeepSeek-R1}: Incentivizing Reasoning Capability in {LLMs} via Reinforcement Learning},
  author  = {{DeepSeek-AI}},
  journal = {arXiv preprint arXiv:2501.12948},
  year    = {2025}
}

@article{geminiteam2024,
  title   = {Gemini 1.5: Unlocking Multimodal Understanding Across Millions of Tokens of Context},
  author  = {{Gemini Team, Google}},
  journal = {arXiv preprint arXiv:2403.05530},
  year    = {2024}
}

@article{xai2024grok,
  title   = {Grok-1},
  author  = {{xAI}},
  journal = {Technical Report},
  note    = {\url{https://x.ai/blog/grok}},
  year    = {2024}
}

@article{qwen2024,
  title   = {{Qwen2.5} Technical Report},
  author  = {{Qwen Team}},
  journal = {arXiv preprint arXiv:2412.15115},
  year    = {2024}
}

@article{qwen3,
  title   = {{Qwen3} Technical Report},
  author  = {{Qwen Team}},
  journal = {arXiv preprint arXiv:2505.09388},
  year    = {2025}
}

@article{phi3,
  title   = {Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone},
  author  = {Abdin, Marah and Jacobs, Sam Ade and Amin, Ammar Ahmad and others},
  journal = {arXiv preprint arXiv:2404.14219},
  year    = {2024}
}

% --- PEFT ---
@inproceedings{houlsby2019adapters,
  title     = {Parameter-Efficient Transfer Learning for {NLP}},
  author    = {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and de Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle = {Proceedings of ICML},
  year      = {2019}
}

@inproceedings{li2021prefix,
  title     = {Prefix-Tuning: Optimizing Continuous Prompts for Generation},
  author    = {Li, Xiang Lisa and Liang, Percy},
  booktitle = {Proceedings of ACL-IJCNLP},
  year      = {2021}
}

@inproceedings{lester2021prompt,
  title     = {The Power of Scale for Parameter-Efficient Prompt Tuning},
  author    = {Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle = {Proceedings of EMNLP},
  year      = {2021}
}

@article{liu2022ia3,
  title   = {Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning},
  author  = {Liu, Haokun and Tam, Derek and Muqeeth, Mohammed and Mohta, Jay and Huang, Tenghao and Bansal, Mohit and Raffel, Colin},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  year    = {2022}
}

@article{liu2024dora,
  title   = {{DoRA}: Weight-Decomposed Low-Rank Adaptation},
  author  = {Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung},
  journal = {arXiv preprint arXiv:2402.09353},
  year    = {2024}
}

% --- Reinforcement Learning ---
@article{shao2024deepseekmath,
  title   = {{DeepSeekMath}: Pushing the Limits of Mathematical Reasoning in Open Language Models},
  author  = {Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and others},
  journal = {arXiv preprint arXiv:2402.03300},
  year    = {2024}
}

% --- Prompting ---
@inproceedings{sel2024aot,
  title     = {Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models},
  author    = {Sel, Bilgehan and Al-Tawaha, Ahmad and Khattar, Vanshaj and Jia, Ruoxi and Jin, Ming},
  booktitle = {Proceedings of ICML},
  year      = {2024}
}

@inproceedings{besta2024got,
  title     = {Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
  author    = {Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and others},
  booktitle = {Proceedings of AAAI},
  year      = {2024}
}

@inproceedings{zheng2024rexgot,
  title     = {Reverse Multi-Choice Dialogue Commonsense Inference with Graph-of-Thought},
  author    = {Zheng, Li and others},
  booktitle = {Proceedings of AAAI},
  year      = {2024}
}

@inproceedings{du2023debating,
  title     = {Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  author    = {Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua B. and Mordatch, Igor},
  booktitle = {Proceedings of ICML},
  year      = {2024}
}

% --- Frameworks ---
@inproceedings{wu2023autogen,
  title     = {{AutoGen}: Enabling Next-Gen {LLM} Applications via Multi-Agent Conversation},
  author    = {Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Li, Beibin and Zhu, Erkang and Jiang, Li and Zhang, Xiaoyun and Zhang, Shaokun and Liu, Jiale and others},
  booktitle = {ICLR 2024 LLM Agents Workshop (Best Paper)},
  year      = {2024}
}

@misc{smolagents2025,
  title        = {smolagents: A Smol Library to Build Great Agents},
  author       = {{Hugging Face}},
  year         = {2025},
  howpublished = {\url{https://huggingface.co/docs/smolagents}}
}

@misc{googleadk2025,
  title        = {Agent Development Kit ({ADK})},
  author       = {{Google}},
  year         = {2025},
  howpublished = {\url{https://google.github.io/adk-docs/}}
}

@misc{openaiagents2025,
  title        = {{OpenAI} Agents {SDK}},
  author       = {{OpenAI}},
  year         = {2025},
  howpublished = {\url{https://openai.github.io/openai-agents-python/}}
}

@misc{semantickernel2024,
  title        = {Semantic Kernel: {AI} Orchestration Framework},
  author       = {{Microsoft}},
  year         = {2024},
  howpublished = {\url{https://learn.microsoft.com/en-us/semantic-kernel/}}
}

% --- Evaluation / Optimization ---
@inproceedings{es2024ragas,
  title     = {{RAGAS}: Automated Evaluation of Retrieval Augmented Generation},
  author    = {Es, Shahul and James, Jithin and Espinosa-Anke, Luis and Schockaert, Steven},
  booktitle = {Proceedings of EACL: System Demonstrations},
  year      = {2024}
}

@inproceedings{khattab2024dspy,
  title     = {{DSPy}: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines},
  author    = {Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and others},
  booktitle = {Proceedings of ICLR},
  year      = {2024}
}

% --- Non-determinism ---
@misc{nondeterminism2024,
  title        = {Defeating Nondeterminism in {LLM} Inference},
  author       = {{Thinking Machines}},
  year         = {2024},
  howpublished = {\url{https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/}}
}

% --- Model Context Protocol ---
@misc{anthropic2024mcp,
  title        = {Introducing the {Model Context Protocol}},
  author       = {{Anthropic}},
  year         = {2024},
  howpublished = {\url{https://www.anthropic.com/news/model-context-protocol}},
  note         = {Open standard for connecting AI assistants to data sources and tools}
}

@misc{hu2022lora,
  title         = {LoRA: Low-Rank Adaptation of Large Language Models},
  author        = {Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
  year          = {2022},
  eprint        = {2106.09685},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2106.09685}
}

@misc{dettmers2023qlora,
  title         = {{QLoRA}: Efficient Finetuning of Quantized {LLMs}},
  author        = {Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
  year          = {2023},
  eprint        = {2305.14314},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2305.14314}
}

@misc{liu2024conspemollm,
  title         = {{ConspEmoLLM}: Conspiracy Theory Detection Using an Emotion-Based Large Language Model},
  author        = {Zhiwei Liu and Boyang Liu and Paul Thompson and Kailai Yang and Sophia Ananiadou},
  year          = {2024},
  eprint        = {2403.06765},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2403.06765}
}

@misc{wei2022finetuned,
  title         = {Finetuned Language Models Are Zero-Shot Learners},
  author        = {Jason Wei and Maarten Bosma and Vincent Y. Zhao and Kelvin Guu and Adams Wei Yu and Brian Lester and Nan Du and Andrew M. Dai and Quoc V. Le},
  year          = {2022},
  eprint        = {2109.01652},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2109.01652}
}

@misc{ouyang2022training,
  title         = {Training language models to follow instructions with human feedback},
  author        = {Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
  year          = {2022},
  eprint        = {2203.02155},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2203.02155}
}

@inproceedings{carbonell1998use,
  title     = {The use of {MMR}, diversity-based reranking for reordering documents and producing summaries},
  author    = {Carbonell, Jaime and Goldstein, Jade},
  booktitle = {Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages     = {335--336},
  year      = {1998},
  publisher = {ACM},
  doi       = {10.1145/290941.291025}
}

@article{krippendorff2011computing,
  title     = {Computing {Krippendorff}'s alpha-reliability},
  author    = {Krippendorff, Klaus},
  year      = {2011},
  url       = {https://repository.upenn.edu/asc_papers/43}
}

@article{mcnemar1947note,
  title   = {Note on the sampling error of the difference between correlated proportions or percentages},
  author  = {McNemar, Quinn},
  journal = {Psychometrika},
  volume  = {12},
  number  = {2},
  pages   = {153--157},
  year    = {1947},
  doi     = {10.1007/BF02295996}
}

@book{efron1993bootstrap,
  title     = {An Introduction to the Bootstrap},
  author    = {Efron, Bradley and Tibshirani, Robert J.},
  year      = {1993},
  publisher = {Chapman \& Hall},
  address   = {New York},
  doi       = {10.1007/978-1-4899-4541-9}
}

@inproceedings{melis2018state,
  title     = {On the State of the Art of Evaluation in Neural Language Models},
  author    = {Melis, G{\'a}bor and Dyer, Chris and Blunsom, Phil},
  booktitle = {Proceedings of the International Conference on Learning Representations},
  year      = {2018},
  url       = {https://openreview.net/forum?id=ByqqinWRb}
}

@book{pennebaker2015liwc,
  title     = {{LIWC2015}: Linguistic Inquiry and Word Count},
  author    = {Pennebaker, James W. and Booth, Roger J. and Boyd, Ryan L. and Francis, Martha E.},
  year      = {2015},
  publisher = {Pennebaker Conglomerates},
  address   = {Austin, TX},
  url       = {https://www.liwc.app}
}

@inproceedings{elsherief2021latent,
  title     = {Latent Hatred: A Benchmark for Understanding Implicit Hate Speech},
  author    = {ElSherief, Mai and Ziems, Caleb and Muchlinski, David and Anupindi, Vaishnavi and Seelman, Jordyn and De Choudhury, Munmun and Yang, Diyi},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages     = {345--363},
  year      = {2021},
  publisher = {Association for Computational Linguistics},
  doi       = {10.18653/v1/2021.emnlp-main.29}
}

@article{zubiaga2018stance,
  title   = {Stance and Rumour Spread: A Case Study of the Ferguson Unrest},
  author  = {Zubiaga, Arkaitz and Liakata, Maria and Procter, Rob},
  journal = {PLOS ONE},
  volume  = {13},
  number  = {1},
  pages   = {e0192301},
  year    = {2018},
  doi     = {10.1371/journal.pone.0192301}
}

@inproceedings{rubin2016detecting,
  title     = {Detecting Humor on Twitter: A Transformed Subsectional Content Analysis},
  author    = {Rubin, Victoria and Conroy, Niall and Chen, Yimin and Cornwell, Sarah},
  booktitle = {Proceedings of the Association for Information Science and Technology},
  volume    = {53},
  number    = {1},
  pages     = {1--5},
  year      = {2016},
  doi       = {10.1002/pra2.2016.14505301042}
}


@article{douglas2019understanding,
  title   = {Understanding Conspiracy Theories},
  author  = {Douglas, Karen M. and Uscinski, Joseph E. and Sutton, Robbie M. and Cichocka, Aleksandra and Nefes, Turhan and Ang, Chee Siang and Deravi, Farzin},
  journal = {Political Psychology},
  volume  = {40},
  number  = {S1},
  pages   = {3--35},
  year    = {2019},
  doi     = {10.1111/pops.12568}
}

@misc{peng2023yarn,
  title         = {{YaRN}: Efficient Context Window Extension of Large Language Models},
  author        = {Bowen Peng and Jeffrey Quesnelle and Honglu Fan and Enrico Shippole},
  year          = {2023},
  eprint        = {2309.00071},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2309.00071}
}

@misc{yao2023tree,
  title         = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
  author        = {Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
  year          = {2023},
  eprint        = {2305.10601},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/2305.10601}
}

@misc{langgraph2024,
  title        = {{LangGraph}: Build Stateful, Multi-Actor Applications with {LLMs}},
  author       = {{LangChain}},
  year         = {2024},
  url          = {https://github.com/langchain-ai/langgraph},
  note         = {Accessed 2024}
}

@misc{pydanticai2024,
  title        = {{Pydantic AI}: Agent Framework for the {Pydantic} Ecosystem},
  author       = {{Pydantic}},
  year         = {2024},
  url          = {https://ai.pydantic.dev/},
  note         = {Accessed 2024}
}

@misc{chromadb2023,
  title        = {{Chroma}: The {AI}-Native Open-Source Embedding Database},
  author       = {{Chroma Core}},
  year         = {2023},
  url          = {https://www.trychroma.com/},
  note         = {Accessed 2024}
}

@misc{bge_m3,
  title        = {{BGE M3-Embedding}: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation},
  author       = {Chen, Jianlv and Xiao, Shitao and Zhang, Peitian and Luo, Kun and Lian, Defu and Liu, Zheng},
  year         = {2024},
  eprint       = {2309.07597},
  archiveprefix= {arXiv},
  primaryclass = {cs.CL},
  url          = {https://arxiv.org/abs/2309.07597}
}

@misc{mlflow2024,
  title        = {{MLflow}: A Platform for the Machine Learning Lifecycle},
  author       = {{MLflow Project}},
  year         = {2024},
  url          = {https://mlflow.org/},
  note         = {Accessed 2024}
}

@misc{agrawal2025gepa,
  title        = {{GEPA}: Gradient-Free Evolutionary Prompt Architecture},
  author       = {Agrawal, Pranjal and Pasunuru, Ramakanth and Celikyilmaz, Asli and Bansal, Mohit},
  year         = {2025},
  eprint       = {2501.07215},
  archiveprefix= {arXiv},
  primaryclass = {cs.CL},
  url          = {https://arxiv.org/abs/2501.07215}
}

@misc{anthropic2025claude,
  title        = {Claude},
  author       = {{Anthropic}},
  year         = {2025},
  url          = {https://www.anthropic.com/claude},
  note         = {Accessed 2025}
}

@inproceedings{carbonell1998mmr,
  title     = {The use of {MMR}, diversity-based reranking for reordering documents and producing summaries},
  author    = {Carbonell, Jaime and Goldstein, Jade},
  booktitle = {Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages     = {335--336},
  year      = {1998},
  publisher = {ACM},
  doi       = {10.1145/290941.291025}
}
