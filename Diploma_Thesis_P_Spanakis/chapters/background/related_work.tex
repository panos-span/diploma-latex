\section{Related Work}
\label{sec:related-work}

\subsection{Conspiracy Detection in NLP}

Early works on NLP conspiratorial discourse on Reddit introduced narrative motifs correlated with conspiratorial evidence \cite{online-discussions} and demonstrated that conspiratorial thinking manifests through detectable psycholinguistic signals in user language \cite{Klein2019Pathways}, with consequent literature revealing that conspiracy theories exhibit distinctive narrative frameworks that can be computationally extracted from text \cite{Tangherlini2020Automated}. These foundational works empowered the operationalization of conspiracy identification as a classification task, exemplified by datasets such as COCO \cite{langguth2023coco} and YouNICon \cite{YouNICon}.

Beyond Reddit-specific corpora, the broader misinformation detection literature has produced benchmark datasets that share structural similarities with conspiracy detection. The LIAR dataset \cite{wang2017liar} introduced multi-class credibility assessment with fine-grained labels, while the Propaganda Techniques Corpus \cite{dasanmartino2019finegrained} operationalized persuasion detection as span-level extraction---a task formulation closely related to our Subtask 1. These works collectively established that misinformation detection benefits from decomposing the problem into interpretable, linguistically-grounded sub-tasks rather than treating it as monolithic binary classification.

More recently, the SemEval shared task ecosystem has driven progress in conspiracy-adjacent NLP challenges. SemEval-2019 Task 6 (OffensEval) \cite{zampieri2019semeval} and SemEval-2020 Task 11 (propaganda detection) \cite{dasanmartino2020semeval2020} demonstrated that structured annotation schemas combined with competitive evaluation protocols catalyze rapid methodological advances. Our participation in SemEval-2026 Task 10 follows this tradition, extending the paradigm to conspiratorial narrative analysis with explicit psycholinguistic grounding.

\subsection{Psycholinguistic Signal Modeling}

Conspiracy detection involves techniques that explicitly model psycholinguistic signals, such as affective tone, attributional cues and explanatory framing, in order to provide explanatory evidence of conspiracy presence in language \cite{rains2023psycholinguistic, language-of-conspiracy-theories, marino-etal-2025-linguistic}. The strong contextualization that LLMs offer inspired the introduction of related approaches; leveraging appropriate prompting enables accurate multi-label conspiracy classification, eliminating training demands \cite{peskine-etal-2023-definitions}. Complementarily, ConspEmoLLM \cite{liu2024conspemollm} involves emotion-aware LLM fine-tuning on several conspiratorial tasks, improving detection by leveraging affective signals, with subsequent extensions focusing on robustness to stylistic and emotional variation \cite{liu2025conspemollmv2}.

The psycholinguistic approach to conspiracy detection is rooted in dictionary-based lexical analysis. The Linguistic Inquiry and Word Count (LIWC) framework \cite{pennebaker2015liwc} has been widely used to quantify psychological dimensions of text, including cognitive complexity, emotional tone, and certainty markers. Studies applying LIWC to conspiracy discourse show significantly elevated rates of causal language (``because'', ``therefore''), certainty markers (``always'', ``definitely''), and third-person plural pronouns (``they'', ``them'') \cite{language-of-conspiracy-theories}. Our Forensic Profiler component operationalizes a subset of these LIWC-inspired features as deterministic signals, bridging traditional psycholinguistic analysis with modern LLM-based reasoning.

Implicit hate speech detection \cite{elsherief2021latent} shares methodological parallels with conspiracy detection, as both require identifying subtle pragmatic signals that distinguish genuine beliefs from ironic or reporting use. Methods developed for implicit hate speech---including contrastive learning on hard negatives and multi-task learning with stance detection---have informed our approach to the Reporter Trap problem, where topical discussion of conspiracies must be distinguished from endorsement.

\subsection{LLM-Based Approaches and Their Limitations}

Recent evaluations indicate that LLM-based conspiracy detection often relies on topical shortcuts and struggles with narrative ambiguity, underscoring the need for approaches grounded in interpretable psycholinguistic markers \cite{pustet-etal-2024-detection, classifying}. Single-pass classifiers have been shown to over-commit early and underweight stance cues \cite{wan-etal-2025-unveiling}, leading to systematic false positives when topical discussion of conspiracies is conflated with endorsement---a failure mode we term the \textit{Reporter Trap}.

LLMs have been found to be significantly prone to cognitive biases \cite{filandrianos-etal-2025-bias} and manipulation via persuasive language \cite{xu-etal-2024-earth}, while they generate and amplify misinformation \cite{chen2024combatingmisinformation}. State-of-the-art LLMs are even able to persuade people to adopt conspiratorial beliefs to a comparable degree as they can mitigate conspiracy dissemination \cite{costello2026largelanguagemodelseffectively}, exposing the double-edged nature of LLMs in the context of factual verification.

A particular challenge for LLM-based classification is the distinction between topical relevance and stance endorsement. When a news article or Reddit submission statement discusses a conspiracy theory in a neutral or debunking context, single-pass LLMs frequently classify it as conspiratorial based on surface-level lexical overlap. This failure mode has been documented across multiple domains, including stance detection in rumor verification \cite{zubiaga2018stance} and satirical news detection \cite{rubin2016detecting}. Our Anti-Echo Chamber architecture explicitly addresses this through adversarial deliberation, where the Defense Attorney persona is specifically tasked with identifying cases where conspiratorial language is used in non-endorsing contexts.

\subsection{Multi-Agent and Agentic LLM Systems}

The concept of orchestrating multiple LLM agents to tackle complex tasks has gained significant traction. Multi-agent debate frameworks have demonstrated improved reasoning through structured disagreement \cite{agent1, agent2, agent3}. Self-refinement patterns, where models critique and revise their own outputs, have shown consistent quality improvements across generation tasks \cite{madaan2023selfrefine}. Our work extends these paradigms to the conspiracy detection domain, introducing the first agentic LLM-based method that combines self-refinement for span extraction with adversarial council deliberation for stance classification.

The multi-agent approach has shown particular promise in tasks requiring diverse perspectives. ChatEval \cite{chan2024chateval} demonstrated that multi-agent evaluation produces more calibrated quality scores than single-agent assessment, while Camel \cite{li2023camel} showed that role-playing agent pairs can autonomously complete complex tasks through structured communication. Our Anti-Echo Chamber extends these ideas by assigning adversarial roles with complementary analytical biases, ensuring that classification decisions are stress-tested against multiple failure modes before a final verdict is reached.

Recent work on agentic planning and tool use has established that LLM agents benefit from explicit decomposition of complex tasks into manageable sub-steps. Toolformer \cite{schick2023toolformer} demonstrated that LLMs can learn to use external tools to augment their capabilities, while the ReAct framework \cite{yao2023react} showed that interleaving reasoning with action improves task completion rates. Our system architecture leverages these insights by combining LLM-based reasoning (Generator, Council) with deterministic tool-like components (Verifier, Profiler) that provide structural guarantees the LLMs cannot offer alone.

\subsection{Span Extraction and Information Extraction}

Character-level span extraction poses unique challenges for LLMs, which excel at semantic reasoning but are brittle at character-accurate localization \cite{fu2024struggle}. Prior work has documented ``hallucinated spans''---outputs that appear plausible but do not match the source text \cite{ogasa-arase-2025-hallucinated}. Our hybrid architecture addresses this by decoupling semantic identification from deterministic span indexing, ensuring structural validity while preserving the LLM's interpretive capabilities.

The span extraction task in our system shares similarities with SQuAD-style extractive question answering \cite{rajpurkar2016squad}, where models must identify exact text passages that answer specific questions. However, conspiracy marker extraction differs in several critical ways: markers may be non-contiguous, multiple markers of different types may overlap within the same passage, and the notion of ``correctness'' involves both semantic appropriateness and character-precise boundary alignment. These additional complexities motivate our five-tier matching cascade in the Deterministic Verifier.

Named Entity Recognition (NER) and event extraction represent related information extraction tasks that have benefited from hybrid neural--rule-based approaches. Recent work on few-shot NER using LLMs \cite{wang2023gptner} has shown that prompting-based approaches can achieve competitive performance with minimal labeled data, but struggle with entity boundary detection---a finding consistent with our observation that LLMs excel at identifying \textit{what} spans to extract but struggle with \textit{where} those spans precisely begin and end in the source text.

\subsection{Prompt Optimization}

The growing complexity of LLM-based pipelines has motivated automated approaches to prompt engineering. Evolutionary strategies applied to prompt optimization treat the search for effective instructions as a combinatorial problem over natural language \cite{agrawal2025gepa}. XML-structured prompting has emerged as a best practice for complex multi-part instructions, with both Anthropic \cite{anthropic2024xml} and OpenAI \cite{openai2024prompting} recommending hierarchical tag-based prompt organization for improved reliability \cite{alpay2025xmlprompting, sambaraju2025xmlstructured, white2023prompt}.

Beyond evolutionary approaches, gradient-free optimization methods for prompts have diversified considerably. DSPy \cite{khattab2023dspy} treats prompting as a declarative programming paradigm, automatically compiling high-level task specifications into optimized prompt chains. EvoPrompt \cite{guo2024evoprompt} applies genetic algorithms and differential evolution to prompt optimization, demonstrating that evolutionary pressure on natural language instructions can consistently improve task performance. APE (Automatic Prompt Engineering) \cite{zhou2023large} uses LLMs themselves to generate and select prompts, creating a self-referential optimization loop.

Our GEPA framework builds upon these foundations while addressing domain-specific challenges. The key innovations include reflection-based mutation (where the LLM analyzes failure patterns rather than applying random perturbations), train/dev alternation to prevent overfitting, and the ``Trojan Horse'' pattern for label passthrough---a technique that exploits the evolutionary framework's evaluation pipeline to simultaneously optimize for multiple objectives without explicit multi-objective optimization.