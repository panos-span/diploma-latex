\chapter*{Abstract}

This thesis presents an agentic LLM system for SemEval-2026 Task 10 that jointly (i) extracts psycholinguistic conspiracy markers as text spans and (ii) classifies whether a Reddit comment endorses a conspiracy theory. The design separates semantic extraction from deterministic span localization and employs an Anti-Echo Chamber council to reduce false positives on reporting and debunking content. For Subtask 1 (Marker Extraction), we introduce Dynamic Discriminative Chain-of-Thought (DD-CoT) reasoning within a Self-Refine loop, where a Generator proposes labeled marker strings, an Enhanced Critic audits them, a Refiner applies corrections, and a Deterministic Verifier anchors each string to character-precise offsets. For Subtask 2 (Conspiracy Detection), we structure classification as adversarial deliberation through a Parallel Council of four specialized personas (Prosecutor, Defense Attorney, Literalist, and Stance Profiler) whose independent votes are aggregated by a Calibrated Judge with conservative confidence rules. Both subtasks leverage Contrastive Few-shot Retrieval, including stratified sampling for marker extraction and hard negative mining for stance discrimination. Prompt templates are optimized using the Genetic Evolution Prompt Algorithm (GEPA). The agentic pipeline doubles S1 macro F1 (from 0.12 to 0.24) and improves S2 macro F1 by 49\% (from 0.53 to 0.79) over a zero-shot GPT-5.2 baseline, demonstrating that workflow structure can substitute for model or data changes in psycholinguistic NLP settings. To the best of our knowledge, this constitutes the first agentic LLM-based method for psycholinguistic conspiracy marker extraction and detection.


\paragraph*{Keywords ---}
Large Language Models (LLMs), agentic workflows, conspiracy detection, psycholinguistic markers, span extraction, multi-agent deliberation, Chain-of-Thought reasoning, self-refinement, contrastive retrieval, prompt optimization, SemEval.