\section{Θεωρητικό Υπόβαθρο}

\subsection{Εισαγωγή στα Μεγάλα Γλωσσικά Μοντέλα}

Τα Μεγάλα Γλωσσικά Μοντέλα (ΜΓΜ) είναι συτήματα τεχνητής νοημοσύνης που εκπαιδεύονται σε τεράστιους όγκους δεδομένων με στόχο την κατανόηση και παραγωγή φυσικής γλώσσας. Βασίζονται κατά κύριο λόγο στην αρχιτεκτονική του Μετασχηματιστή (Transformer) \cite{vaswani2023attentionneed}, η οποία με τη χρήση μηχανισμών αυτοπροσοχής επιτρέπει την αποδοτική μοντελοποίηση των εννοιολογικών σχέσεων μεταξύ λέξεων ή συμβόλων σε ένα κείμενο, ανεξάρτητα από τη θέση τους σε αυτό, αναβαθμίζοντας σημαντικά τις επιδόσεις των μοντέλων σε εργασίες επεξεργασίας φυσικής γλώσσας \cite{llmsurvey}. Τα κείμενα εισάγονται στα μοντέλα ως ακολουθίες από tokens, τα οποία μπορεί να είναι σύμβολα, λέξεις ή υπολέξεις, και η εκπαίδευση των ΜΓΜ βασίζεται ουσιαστικά στην πρόβλεψη του επόμενου token μέσω τεχνικών αυτο-επιβλεπόμενης μάθησης \cite{10.3115/992424.992434}. Αν και τα μοντέλα αποκτούν ήδη αξιόλογες ικανότητες κατά το στάδιο της προεκπαίδευσης (\cite{brown2020languagemodelsfewshotlearners}; \cite{chowdhery2022palmscalinglanguagemodeling}), σε πολλές περιπτώσεις, για να ενισχυθεί η απόδοσή τους εφαρμόζονται τεχνικές στοχευμένης βελτιστοποίησης (fine-tuning) \cite{llmoverview} όπως η μεταφορά μάθησης (\cite{transferlearningsurvey}; \cite{transferlearning}), η εκπαίδευση με οδηγίες (\cite{instructiontuninglargelanguage}; \cite{instruction}; \cite{finetunedlanguagemodelszeroshot}) ή η ευθυγράμμιση μέσω ανθρώπινης ανατροφοδότησης (RLHF) \cite{rlhf}. Τα ΜΓΜ, διευρύνοντας τις δυνατότητες της τεχνητής νοημοσύνης σε πρωτοφανή βαθμό, από απλοί παραγωγοί κειμένου αναδεικνύονται πλέον ως ισχυρά εργαλεία γενικής χρήσης, ικανά να επιλύουν σύνθετα γνωσιακά προβλήματα με εντυπωσιακές επιδόσεις που πλησιάζουν ή και ξεπερνούν το ανθρώπινο επίπεδο \cite{surveylargelanguagemodels}. 

Η προεκπαίδευση των ΜΓΜ τυπικά περιλαμβάνει δεκάδες εώς και εκατοντάδες δισεκατομμύρια παραμέτρους, οι οποίες διαμορφώνονται για να βελτιστοποιήσουν την ικανότητα των μοντέλων να προβλέπουν σωστά \cite{parameters}. Η εμπειρική έρευνα στη μοντελοποίηση γλώσσας έχει δείξει πως υπάρχει σαφής και συστηματικά σχέση μεταξύ του μεγέθος των ΜΓΜ και της απόδοσής τους, με τα μεγαλύτερα μοντέλα να επιτυγχάνουν καλύτερα αποτελέσματα σε ένα ευρύ φάσμα εφαρμογών (\cite{Radford2019LanguageMA}; \cite{chowdhery2022palmscalinglanguagemodeling}). Μάλιστα, αυτό το φαινόμενο έχει αποτυπωθεί ποσοτικά μέσα από τους αποκαλούμενους νόμους κλιμάκωσης (scaling laws), οποίοι περιγράφουν πώς η απόδοση των μοντέλων ακολουθεί προβλέψιμη πορεία βελτίωσης καθώς αυξάνονται τρεις βασικοί παράγοντες: το μέγεθος του μοντέλου (αριθμός παραμέτρων), το μέγεθος του συνόλου δεδομένων και η διαθέσιμη υπολογιστική ισχύς. Μελέτες όπως των Kaplan et al. \cite{scalinglawsneurallanguage} και Hoffmann et al. \cite{hoffmann2022trainingcomputeoptimallargelanguage} διατύπωσαν διαφορετικές προσεγγίσεις, αλλά κατέληξαν στο ίδιο συμπέρασμα: ότι η κλιμάκωση των ΜΓΜ οδηγεί σε προβλέψιμες και σημαντικές βελτιώσεις απόδοσης. Έτσι, οι νόμοι κλιμάκωσης έχουν καταστεί πλέον θεμέλιο για την ανάπτυξη των όλο και μεγαλύτερων σύγχρονων, υψηλών επιδόσεων γλωσσικών μοντέλων.

Είναι σαφές, λοιπόν, ότι τα ΜΓΜ με την αύξηση της κλίμακάς τους έχουν σημειώσει εντυπωσιακή πρόοδο σε τυπικές εργασίες επεξεργασίας φυσικής γλώσσας (\cite{translation1}; \cite{sum-benchmarking}; \cite{sentiment1}; \cite{textclassification}; \cite{qa1}), αλλά και σε νέες, πολυπρακτικές (\cite{modal1}; \cite{modal2}) και πολυπρακτορικές (\cite{agent1}; \cite{agent2}; \cite{agent3}) εφαρμογές. Βέβαια, ένα από τα πιο αξιοσημείωτα χαρακτηριστικά αυτών των μοντέλων είναι η εμφάνιση ικανοτήτων που δεν προβλέπονται από τους νόμους κλιμάκωσης και δεν παρατηρούνται σε μικρότερα μοντέλα, αλλά εκδηλώνονται απότομα όταν το μέγεθος ξεπεράσει ένα συγκεκριμένο κατώφλι (\cite{emergent}; \cite{imitation}). Τέτοιες "αναδυόμενες" συμπεριφορές περιλαμβάνουν, μεταξύ άλλων, τη μάθηση εντός συμφραζομένων (in-context learning) (\cite{incontextlearning}; \cite{incon}), την παραγωγή προγραμμάτων (code generation) (\cite{code_gen1}; \cite{code_gen2}), την εκτέλεση πολύπλοκής συλλογιστικής \cite{reasoningsurvey} και την επίλυση γρίφων \cite{puzzle}.

\subsection{Μηχανική Προτροπών}

Η προτροπή (prompting) περιλαμβάνει τη διατύπωση οδηγιών ή ενδείξεων που λειτουργούν ως είσοδοι προς το μοντέλο με στόχο την παραγωγή ορθών απαντήσεων χωρίς την ανάγκη αναπροσαρμογής των παραμέτρων του. Η συστηματική πρακτική σχεδιασμού και διατύπωσης αυτών των οδηγιών με τρόπο που οδηγεί αποδοτικά τη συμπεριφορά των μοντέλων προς την επιθυμητή κατεύθυνση ονομάζεται μηχανική προτροπών (prompt engineering) και έχει καθιερωθεί ως κρίσιμο εργαλείο για τη μεγιστοποίηση των δυνατοτήτων των ΜΓΜ, καθώς επιτρέπει την ευέλικτη προσαρμογή σε διαφορετικές εργασίες, αποφεύγοντας χρονοβόρες διαδικασίες εκπαίδευσης (\cite{promptreportsystematicsurvey}; \cite{systematicsurveypromptengineering}). Βέβαια, τα ΜΓΜ είναι ιδιαίτερα ευαίσθητα στην ακριβή διατύπωση των εισόδων, γεγονός που καθιστά την σωστή σχεδίαση καθοριστική πρόκληση (\cite{promptreportsystematicsurvey}; \cite{liu2021pretrainpromptpredictsystematic}).

Με σκοπό την εύρεση του "πιο κατάλληλου prompt", που θα εκμαιεύσει την επιθυμητή απόκριση από το μοντέλο, έχουν αναπτυχθεί διαφορετικές τεχνικές προτροπών. Ανάμεσα στις βασικότερες από αυτές είναι η τεχνική με μηδενικά παραγείγματα (Zero-Shot), στην οποία περιλαμβάνεται αποκλειστικά η οδηγία για την εκλπήρωση της εκάστοτε εργασίας \cite{systematicsurveypromptengineering}, οι τεχνικές ενός ή λίγων παραδειγμάτων (One-Shot και Few-Shot), όπου το μοντέλο λαμβάνει ένα ή περισσότερα παραδείγματα επιτυχημένης εκτέλεσης αντίστοιχα \cite{brown2020languagemodelsfewshotlearners}, και η προτροπή με αλυσίδες σκέψης (Chain-of-Thought), που ενθαρρύνει τα ΜΓΜ να εφκράσουν την συλλογιστική τους πορεία μέσα από ενδιάμεσα βήματα (\cite{cotpromptingelicitsreasoning}; \cite{understandingchainofthoughtpromptingempirical}). Επίσης, για να διευκολυνθεί η αλληλεπίδραση με τα μοντέλα και να υποστηριχθεί η εφαρμογή τους σε εργασίες μεγάλης κλίμακας, συνήθως χρησιμοποιούνται πρότυπα προτροπών, δηλαδή παραμετροποιημένες δομές εισόδου στις οποίες ενσωματώνονται μεταβλητές που αντικαθίστανται κατά την πειραματική διαδικασία (\cite{templates}; \cite{promptreportsystematicsurvey}).

\subsection{Αξιολόγηση με ΜΓΜ}

Καθώς τα ΜΓΜ εξελίσσονται και εφαρμόζονται σε ένα ευρύ φάσμα γνωστικών πεδίων, γίνεται ολοένα και πιο επιτακτική η ανάγκη για αξιόπιστη και αποδοτική αξιολόγηση της απόδοσής τους. Οι παραδοσιακές μετρικές, όπως η ακρίβεια ή η ανάκληση, επαρκούν μόνο για περιορισμένο αριθμό εφαρμογών με συγκεκριμένα χαρακτηριστικά, ενώ ακόμα και πιο εξελιγμένες, όπως οι BLEU, ROUGE και METEOR αποτυγχάνουν να αποτυπώσουν ποιοτικά χαρακτηριστικά των γενετικών απαντήσεων των ΜΓΜ (\cite{gu2025surveyllmasajudge}; \cite{llmsasjudgescomprehensivesurveyllmbased}). Επίσης, η ανθρώπινη αξιολόγηση, παρόλο που θεωρείται η πιο αξιόπιστη λύση, είναι ιδιαίτερα δαπανηρή και δύσκολα επεκτάσιμη (\cite{gu2025surveyllmasajudge}; \cite{llmsasjudgescomprehensivesurveyllmbased}). Μία καινοτόμος προσέγγιση είναι η χρήση των ίδιων των ΜΓΜ ως αξιολογητών, γνωστή και ως LLM-as-a-judge \cite{zheng2023judgingllmasajudgemtbenchchatbot}. Σε αυτό το πλαίσιο, τα μοντέλα καθοδηγούνται μέσω ειδικά σχεδιασμένων προτροπών ώστε να εκτιμούν την ποιότητα των απαντήσεων βάσει συγκεκριμένων κριτηρίων που καθορίζονται ανάλογα με τους στόχους κάθε εργασίας \cite{llmsasjudgescomprehensivesurveyllmbased}. Τα μοντέλα μπορούν να λειτουργούν μόνα τους (\cite{single-eval1}; \cite{single-eval2}; \cite{single-eval3}), σε συνδυασμό με άλλα ΜΓΜ (\cite{multi-eval1}; \cite{multi-eval2}; \cite{multi-eval3}) ή και σε συνεργασία με ανθρώπους (\cite{colab1}; \cite{colab2}), πετυχαίνοντας αποτελέσματα που συχνά είναι πολύ κοντά στις ανθρώπινες κρίσεις (\cite{code1}; \cite{freitag-etal-2021-results}; \cite{fluency1}; \cite{fluency2}; \cite{dialogue}; \cite{mllm}; \cite{mmevalmultilingualmetaevaluationbenchmark}). 

Παρα τις υποσχέσεις της, ωστόσο, το ερώτημα της αξιοπιστίας αυτής της μεθόδου παραμένει, με την ερευνητική κοινότητα να στρέφεται σε τεχνικές μετα-αξιολόγησης (meta-evaluation), προκειμένου να μετρήσει τη συμφωνία μεταξύ ΜΓΜ-κριτών και ανθρώπινων προτιμήσεων και να εντοπίσει συστημικές προκαταλήψεις \cite{llmsasjudgescomprehensivesurveyllmbased}, οι οποίες μπορεί να σχετίζονται, για παράδειγμα, με τη θέση, την έκταση ή το κύρος των απαντήσεων (\cite{zheng2023judgingllmasajudgemtbenchchatbot}; \cite{ye2024justiceprejudicequantifyingbiases}). Τα αποτελέσματα είναι ενθαρρυντικά: τα ΜΓΜ μπορούν, με κατάλληλη καθοδήγηση, να λειτουργήσουν ως αξιόπιστοι και ευέλικτοι αξιολογητές, προσφέροντας ένα βιώσιμο εναλλακτικό εργαλείο όταν οι παραδοσιακές πρακτικές δεν επαρκούν ή δεν είναι πρακτικά εφαρμόσιμες.

\subsection{Συλλογιστική στα ΜΓΜ}

Μεγάλο ενδιαφέρον έχει προκληθεί σχετικά με το κατά πόσο τα ΜΓΜ μπορούν να επιδείξουν γνήσιες δυνατότητες λογικής σκέψης \cite{reasoning-machine}. Η πρόσφατη έρευνα έχει επικεντρωθεί σε διάφορες μορφές συλλογιστικής \cite{reasoningsurvey}, όπως η επαγωγική (\cite{li2025mirageevaluatingexplaininginductive}; \cite{bowen-etal-2024-inductive}), η παραγωγική (\cite{chen2025justlogiccomprehensivebenchmarkevaluating}; \cite{clark2020transformerssoftreasonerslanguage}), η αιτιατική (\cite{jin2024largelanguagemodelsinfer}; \cite{causalbench}), η αναλογική (\cite{qin2024relevantrandomllmstruly}; \cite{sultan2023lifecircusclownsautomatically}), η αριθμητική σκέψη (\cite{mishra2023lilaunifiedbenchmarkmathematical}; \cite{wang-lu-2023-learning}) και η κοινή λογική (\cite{commonsenseqa}; \cite{commonsense}). Αν και η πρόοδος σε αυτούς τους τομείς είναι αξιοσημείωτη, η ικανότητα συλλογιστικής των ΜΓΜ παραμένει περιορισμένη, ειδικά όταν συγκρίνεται με την επιτυχία τους σε παραδοσιακές γλωσσικές εφαρμογές \cite{mahowald2024dissociatinglanguagethoughtlarge}. Το χάσμα αυτό, μάλιστα, γίνεται ακόμα πιο εμφανές όταν τα μοντέλα καλούνται να απαντήσουν σε ερωτήματα που παρουσιάζονται σε ασυνήθιστες μορφές, υπό παραπλανητικά συμφραζόμενα ή περιέχουν υποθετικές δηλώσεις και πληροφορίες που αντιβαίνουν στη γενική γνώση (\cite{reasoningrecitingexploringcapabilities}; \cite{li2023counterfactualreasoningtestinglanguage}; \cite{yu2023ifqadatasetopendomainquestion}; \cite{adaptability}). Η αδυναμία αυτή υποδηλώνει περιορισμένη γνωστική προσαρμοστικότητα, με τα ΜΓΜ συχνά να "παπαγαλίζουν" πρότυπα ή δεδομένα που έχουν εσωτερικεύσει κατά την εκπαίδευσή τους. Έτσι, πρόσφατη έρευνα αποδίδει τις επιτυχίες τους περισσότερο στην απομνημόνευση παραδειγμάτων και την αντιστοίχιση μοτίβων, παρά σε γνήσια κατανόηση και ικανότητα. Μελέτες στρέφονται προς μεθόδους αξιολόγησης των μοντέλων που διαχωρίζουν την απομνημόνευση από την αυθεντική λογική σκέψη, ώστε να κατανοηθεί καλύτερα η πραγματική φύση της "νοημοσύνης" που επιδεικνύουν τα ΜΓΜ (\cite{xie2025memorizationlargelanguagemodels}; \cite{lou2024quantifyingincontextreasoningeffects}; \cite{wang2025generalizationvsmemorizationtracing}).

\subsection{Προβλήματα αντίστροφης κλιμάκωσης}

Παρόλο που η αύξηση του μεγέθους των γλωσσικών μοντέλων οδηγεί συνήθως σε καλύτερη απόδοση \cite{scalinglawsneurallanguage}, πρόσφατες μελέτες έχουν εντοπίσει περιπτώσεις στις οποίες συμβαίνει το αντίθετο: τα μεγαλύτερα μοντέλα αποδίδουν χειρότερα από τα μικρότερα. Αυτό το παράδοξο φαινόμενο ονομάζεται αντίστροφη κλιμάκωση (inverse scaling) και εκθέτει τις αδυναμίες ακόμα και των πιο ισχυρών ΜΓΜ, αποκαλύπτοντας αποκλίσεις μεταξύ των συλλογιστικών διαδικασιών τους και των ανθρώπινων επιδόσεων. Για να μελετηθούν συστηματικά τέτοιες περιπτώσεις, θεσπίστηκε ο διαγωνισμός Inverse Scaling Prize \cite{inversescalingbiggerisnt}, όπου συλλέχθηκαν εργασίες στις οποίες τα μεγαλύτερα μοντέλα αποτυγχάνουν συστηματικά και ταξινομήθηκαν σε τέσσερις κατηγορίες βάσει των πιθανών αιτιών που προκαλούν το συγκεκριμένο φαινόμενο. Οι κατήγορίες αυτές είναι:

\begin{enumerate}
    \item \textbf{Ισχυρά Προκαθορισμένα Προηγούμενα (Strong Prior)}: Το μοντέλο δυσκολεύεται να παρακάμψει τη γνώση που έχει μάθει κατά την προεκπαίδευση, ακόμα και όταν αυτό ζητείται ρητά από τις οδηγίες. 
    \item \textbf{Ανεπιθύμητη Μίμηση (Unwanted Imitation)}: Τα μοντέλα μιμούνται λογικά σφάλματα ή μεροληψίες που περιέχονται στα δεδομένα προεκπαίδευσης.
    \item \textbf{Παραπλανητικά Ερεθίσματα (Distractor Tasks)}: Οι προτροπές περιλαμβάνουν έμμεσα πιο εύκολες, αλλά παραπλανητικές εναλλακτικές εργασίες, στις οποίες τα μοντέλα τείνουν να δίνουν προτεραιότητα λόγω της εξοικείωσής τους με παρόμοια μοτίβα.
    \item \textbf{Ψευδείς Ενδείξεις από Παραδείγματα (Spurious Few-Shot)}: Τα παραδείγματα που παρέχονται στις προτροπές οδηγούν το μοντέλο σε λανθασμένα μοτίβα, τα οποία τείνουν να ακολουθούν μηχανικά, αγνοώντας τη λογική του ερωτήματος.
\end{enumerate}

Η παρούσα εργασία επικεντρώνεται στο πρόβλημα του επαναορισμού (Redefinition), το οποίο εντάσσεται στην κατηγορία των Ισχυρά Προκαθορισμένων Προηγουμένων και απαιτεί την υιοθέτηση ενός εναλλακτικού ορισμού μίας γνωστής έννοιας. Προτείνουμε ότι η εργασία αυτή ως χαρακτηρική περίπτωση του φαινομένου αντίστροφης κλιμάκωσης χρήζει συστηματικής διερεύνησης. Προς αυτήν την κατεύθυνση δημιουργούμε δύο εξειδικευμένα σύνολα δεδομένων που εξετάζουν επαναπροσδιορισμούς σε διαφορετικά σημασιολογικά πεδία και σενάρια και αξιολογούμε την επίδοση σύγχρονων ΜΓΜ, αναλύοντας τις μεταβολές στις συμπεριφορές τους σε σχέση με το μέγεθός τους.